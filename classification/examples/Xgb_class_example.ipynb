{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54188b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3363fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import os            ##  This module is for \"operating system\" interfaces\n",
    "import sys           ##  This module is for functionality relevant to the python run time\n",
    "path_to_datafolder = 'C:/Users/mjdom/source/repos/mdst_nlp_2021/data'\n",
    "print(os.listdir(path_to_datafolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c019cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_datafolder+'/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e62f21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"].copy()\n",
    "#X = df[\"text\"]\n",
    "\n",
    "authors = df[\"author\"].copy()\n",
    "\n",
    "# Label data\n",
    "y = []\n",
    "for author in authors:\n",
    "    if author == \"EAP\":\n",
    "        y.append([1, 0, 0])\n",
    "    if author == \"HPL\":\n",
    "        y.append([0, 1, 0])\n",
    "    if author == \"MWS\":\n",
    "        y.append([0, 0, 1])\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "y_one_vector = []\n",
    "for author in authors:\n",
    "    if author == \"EAP\":\n",
    "        y_one_vector.append(0)\n",
    "    if author == \"HPL\":\n",
    "        y_one_vector.append(1)\n",
    "    if author == \"MWS\":\n",
    "        y_one_vector.append(2)\n",
    "\n",
    "y_one_vector = np.array(y_one_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e29554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0121d4",
   "metadata": {},
   "source": [
    "### Convert text to Td-Idf encoding, sparse tensors to save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae4f4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000000\n",
    "tfidf_vec = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode='tf_idf', sparse=True, ngrams=1)\n",
    "with tf.device('/device:CPU:0'):\n",
    "    tfidf_vec.adapt(X)\n",
    "vocab = tfidf_vec.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bd8449ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf = tf.keras.Sequential([\n",
    "    tfidf_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8352422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3916, 25412])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sparce = tdidf.predict(X_train)\n",
    "x_test_sparce = tdidf.predict(X_test)\n",
    "x_test_sparce.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aea448",
   "metadata": {},
   "source": [
    "### Covert Tensorflow Sparse tensor to Scipy sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "833a282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row  = np.array(x_train_sparce.indices[:,0])\n",
    "col  = np.array(x_train_sparce.indices[:,1])\n",
    "data = np.array(x_train_sparce.values)\n",
    "x_xgb_train = scipy.sparse.coo_matrix((data, (row, col)), shape=(x_train_sparce.shape.as_list()))\n",
    "\n",
    "\n",
    "row_test  = np.array(x_test_sparce.indices[:,0])\n",
    "col_test  = np.array(x_test_sparce.indices[:,1])\n",
    "data_test = np.array(x_test_sparce.values)\n",
    "x_xgb_test = scipy.sparse.coo_matrix((data_test, (row_test, col_test)), shape=(x_test_sparce.shape.as_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b561d59",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5805b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.04892\tvalidation_1-mlogloss:1.05066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:0.48433\tvalidation_1-mlogloss:0.60713\n",
      "[400]\tvalidation_0-mlogloss:0.36113\tvalidation_1-mlogloss:0.54313\n",
      "[600]\tvalidation_0-mlogloss:0.28897\tvalidation_1-mlogloss:0.51552\n",
      "[800]\tvalidation_0-mlogloss:0.24070\tvalidation_1-mlogloss:0.50595\n",
      "[864]\tvalidation_0-mlogloss:0.22870\tvalidation_1-mlogloss:0.50653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=2000, n_jobs=12, num_class=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(x_xgb_train, np.argmax(y_train,axis = 1)), (x_xgb_test, np.argmax(y_test,axis = 1))]\n",
    "eval_set = [(x_xgb_train, np.argmax(y_train,axis = 1)), (x_xgb_test, np.argmax(y_test,axis = 1))]\n",
    "\n",
    "clf = xgb.XGBClassifier( colsample_bytree = .7,\n",
    "                        subsample = .8,\n",
    "                        learning_rate = 0.5,\n",
    "                        max_depth = 3,\n",
    "                        num_class =3,\n",
    "                        objective ='multi:softprob',\n",
    "\n",
    "                        n_estimators =2000,)\n",
    "\n",
    "clf.fit(x_xgb_train, np.argmax(y_train,axis = 1),  early_stopping_rounds=50, eval_metric=[ \"mlogloss\"], eval_set=eval_set,verbose=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ccd29b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9784038 , 0.00949988, 0.01209638],\n",
       "       [0.58568215, 0.07392627, 0.34039158],\n",
       "       [0.46202946, 0.43839046, 0.09958004],\n",
       "       ...,\n",
       "       [0.00837678, 0.9861479 , 0.00547531],\n",
       "       [0.03780356, 0.96076554, 0.00143095],\n",
       "       [0.7275311 , 0.21573621, 0.05673267]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(x_xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97dc2ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss: 0.5051460360975915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print('log loss:',log_loss(y_test,clf.predict_proba(x_xgb_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e7f9f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7967313585291114\n"
     ]
    }
   ],
   "source": [
    "print('accuracy',np.sum(np.argmax(clf.predict_proba(x_xgb_test), axis = 1)== np.argmax(y_test,axis = 1))/len(np.argmax(y_test,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674214c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36cc504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195518d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1ccb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
