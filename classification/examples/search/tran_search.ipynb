{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1638292375217,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "UVEBXpzXyXFy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1638292382354,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "EcAkXOn2yquG",
    "outputId": "4c1ae479-ce4b-4e3c-8915-bba3d5b2e401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638292382898,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "8zIZeD45ysb3",
    "outputId": "2acb8768-bc95-4142-e78c-fde3d1e9282e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os            ##  This module is for \"operating system\" interfaces\\nimport sys           ##  This module is for functionality relevant to the python run time\\n\\nGOOGLE_PATH_AFTER_MYDRIVE = \\'NLP_Textcat/spooky_data/train\\'\\nGOOGLE_DRIVE_PATH = os.path.join(\\'drive\\',\\'My Drive\\', GOOGLE_PATH_AFTER_MYDRIVE)\\nprint(os.listdir(GOOGLE_DRIVE_PATH))\\n\\n# Append the directory path of this notebook to what python easily \"sees\"\\nsys.path.append(GOOGLE_DRIVE_PATH)\\n\\n# Make your current working direct\\nGOOGLE_DRIVE_PATH'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os            ##  This module is for \"operating system\" interfaces\n",
    "import sys           ##  This module is for functionality relevant to the python run time\n",
    "\n",
    "GOOGLE_PATH_AFTER_MYDRIVE = 'NLP_Textcat/spooky_data/train'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive','My Drive', GOOGLE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "\n",
    "# Append the directory path of this notebook to what python easily \"sees\"\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "# Make your current working direct\n",
    "GOOGLE_DRIVE_PATH'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import os            ##  This module is for \"operating system\" interfaces\n",
    "import sys           ##  This module is for functionality relevant to the python run time\n",
    "path_to_datafolder = 'C:/Users/mjdom/source/repos/mdst_nlp_2021/data'\n",
    "print(os.listdir(path_to_datafolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638292383069,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "a3skTZFLyyo4",
    "outputId": "5b76bf55-097f-4264-aeda-9b115852fa8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(path_to_datafolder+ '/train.csv')\n",
    "df_kaggle = pd.read_csv(path_to_datafolder + '/test.csv')\n",
    "df_kaggle.head()\n",
    "\n",
    "#np.hstack((X,df_kaggle['text']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1638292383436,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "suOy8JIcy0g_"
   },
   "outputs": [],
   "source": [
    "X = df[\"text\"].copy()\n",
    "#X = df[\"text\"]\n",
    "\n",
    "authors = df[\"author\"].copy()\n",
    "\n",
    "# Label data\n",
    "y = []\n",
    "for author in authors:\n",
    "    if author == \"EAP\":\n",
    "        y.append([1, 0, 0])\n",
    "    if author == \"HPL\":\n",
    "        y.append([0, 1, 0])\n",
    "    if author == \"MWS\":\n",
    "        y.append([0, 0, 1])\n",
    "\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1638292384200,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "_EdrXElay4Kf"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1901,
     "status": "ok",
     "timestamp": 1638292386313,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "-vlAj1Nyy_Z_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "sequence_length = 100\n",
    "max_features = 1000000\n",
    "# Token locations\n",
    "Vectorizer_transformer = tf.keras.layers.TextVectorization(max_tokens=max_features,output_sequence_length=sequence_length) \n",
    "Vectorizer_transformer.adapt(np.hstack((X,df_kaggle['text'])))\n",
    "vocab = Vectorizer_transformer.get_vocabulary()\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "def create_model(embed_dim=32,num_heads = 2,ff_dim = 32,dropout_rate = 0.2):\n",
    "    \n",
    "    # create model\n",
    "    tf.keras.backend.clear_session()\n",
    "    K.clear_session()\n",
    "    #gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    maxlen = sequence_length\n",
    "\n",
    "    ## Build embedding and transformer\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim,dropout_rate)\n",
    "\n",
    "    ## Connect Keras Layers\n",
    "    inputs = tf.keras.Input(shape=(1,), dtype=tf.string) \n",
    "    vec = Vectorizer_transformer(inputs)\n",
    "    x = embedding_layer(vec)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "    transformer = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    transformer.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import types\\nimport copy\\nclass KerasClassifier(KerasClassifier):\\n    \"\"\" adds sparse matrix handling using batch generator\\n    \"\"\"\\n    \\n    def fit(self, x, y, **kwargs):\\n        \"\"\" adds sparse matrix handling \"\"\"\\n        #if not issparse(x):\\n        #    return super().fit(x, y, **kwargs)\\n        \\n        ############ adapted from KerasClassifier.fit   ######################   \\n        if self.build_fn is None:\\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\\n        elif not isinstance(self.build_fn, types.FunctionType):\\n            self.model = self.build_fn(\\n                **self.filter_sk_params(self.build_fn.__call__))\\n        else:\\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\\n \\n        loss_name = self.model.loss\\n        if hasattr(loss_name, \\'__name__\\'):\\n            loss_name = loss_name.__name__\\n        if loss_name == \\'categorical_crossentropy\\' and len(y.shape) != 2:\\n            y = to_categorical(y)\\n        ### fit => fit_generator\\n        fit_args = copy.deepcopy(self.filter_sk_params(keras.Model.fit_generator))\\n        print(\\'gen\\')\\n        fit_args.update(kwargs)\\n        ############################################################\\n        self.model.fit_generator(\\n                    self.get_batch(x, y, self.sk_params[\"batch_size\"]),\\n                                        steps_per_epoch=x.shape[0],\\n                                        **fit_args)                      \\n        return self                               \\n \\n    def get_batch(self, x, y=None, batch_size=32):\\n        \"\"\" batch generator to enable sparse input \"\"\"\\n        index = np.arange(x.shape[0])\\n        start = 0\\n        while True:\\n            if start == 0 and y is not None:\\n                np.random.shuffle(index)\\n            batch = index[start:start+batch_size]\\n            if y is not None:\\n                yield x[batch].toarray(), y[batch]\\n            else:\\n                yield x[batch].toarray()\\n            start += batch_size\\n            if start >= x.shape[0]:\\n                start = 0\\n   \\n    def predict_proba(self, x):\\n        \"\"\" adds sparse matrix handling \"\"\"\\n        if not issparse(x):\\n            return super().predict_proba(x)\\n            \\n        preds = self.model.predict_generator(\\n                    self.get_batch(x, None, self.sk_params[\"batch_size\"]), \\n                                               val_samples=x.shape[0])\\n        return preds'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import types\n",
    "import copy\n",
    "class KerasClassifier(KerasClassifier):\n",
    "    \"\"\" adds sparse matrix handling using batch generator\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, x, y, **kwargs):\n",
    "        \"\"\" adds sparse matrix handling \"\"\"\n",
    "        #if not issparse(x):\n",
    "        #    return super().fit(x, y, **kwargs)\n",
    "        \n",
    "        ############ adapted from KerasClassifier.fit   ######################   \n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif not isinstance(self.build_fn, types.FunctionType):\n",
    "            self.model = self.build_fn(\n",
    "                **self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    " \n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "        ### fit => fit_generator\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(keras.Model.fit_generator))\n",
    "        print('gen')\n",
    "        fit_args.update(kwargs)\n",
    "        ############################################################\n",
    "        self.model.fit_generator(\n",
    "                    self.get_batch(x, y, self.sk_params[\"batch_size\"]),\n",
    "                                        steps_per_epoch=x.shape[0],\n",
    "                                        **fit_args)                      \n",
    "        return self                               \n",
    " \n",
    "    def get_batch(self, x, y=None, batch_size=32):\n",
    "        \"\"\" batch generator to enable sparse input \"\"\"\n",
    "        index = np.arange(x.shape[0])\n",
    "        start = 0\n",
    "        while True:\n",
    "            if start == 0 and y is not None:\n",
    "                np.random.shuffle(index)\n",
    "            batch = index[start:start+batch_size]\n",
    "            if y is not None:\n",
    "                yield x[batch].toarray(), y[batch]\n",
    "            else:\n",
    "                yield x[batch].toarray()\n",
    "            start += batch_size\n",
    "            if start >= x.shape[0]:\n",
    "                start = 0\n",
    "   \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\" adds sparse matrix handling \"\"\"\n",
    "        if not issparse(x):\n",
    "            return super().predict_proba(x)\n",
    "            \n",
    "        preds = self.model.predict_generator(\n",
    "                    self.get_batch(x, None, self.sk_params[\"batch_size\"]), \n",
    "                                               val_samples=x.shape[0])\n",
    "        return preds'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1638292397051,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "9U7qjqy4zKjw",
    "outputId": "636a0032-65fd-4f14-8b6f-c19921ec6dfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjdom\\AppData\\Local\\Temp/ipykernel_17948/1202741136.py:8: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, batch_size=64, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# fix random seed for reproducibility\n",
    "seed = 15\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=64, verbose=0)\n",
    "# define the grid search parameters\n",
    "embed_dim = [32,64,128,256]\n",
    "num_heads = [1,2]\n",
    "ff_dim =  [32,64,128,256]\n",
    "dropout_rate = [0.0,0.1,0.2,0.3]\n",
    "epochs = [1,2]\n",
    "\n",
    "param_grid = dict(embed_dim=embed_dim,num_heads = num_heads,ff_dim = ff_dim,\n",
    "                  dropout_rate = dropout_rate, epochs=epochs)\n",
    "#grid = GridSearchCV(estimator=model, scoring = 'neg_log_loss', param_grid=param_grid, n_jobs=1, cv=3, verbose=3)\n",
    "grid = RandomizedSearchCV(model, param_grid, n_iter=2,scoring = 'neg_log_loss', n_jobs=1, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 745863,
     "status": "ok",
     "timestamp": 1638293143326,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "IsLCl8ca0Nzs",
    "outputId": "ee56a225-f046-4496-ed71-277a6c128de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END dropout_rate=0.2, embed_dim=32, epochs=2, ff_dim=128, num_heads=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END dropout_rate=0.2, embed_dim=32, epochs=2, ff_dim=128, num_heads=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END dropout_rate=0.2, embed_dim=32, epochs=2, ff_dim=128, num_heads=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END dropout_rate=0.2, embed_dim=32, epochs=2, ff_dim=128, num_heads=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END dropout_rate=0.2, embed_dim=32, epochs=2, ff_dim=128, num_heads=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END dropout_rate=0.2, embed_dim=32, epochs=1, ff_dim=128, num_heads=2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END dropout_rate=0.2, embed_dim=32, epochs=1, ff_dim=128, num_heads=2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END dropout_rate=0.2, embed_dim=32, epochs=1, ff_dim=128, num_heads=2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END dropout_rate=0.2, embed_dim=32, epochs=1, ff_dim=128, num_heads=2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END dropout_rate=0.2, embed_dim=32, epochs=1, ff_dim=128, num_heads=2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 232, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"C:\\Users\\mjdom\\AppData\\Local\\Temp/ipykernel_8320/2031994828.py\", line 16, in create_model\n",
      "    tf.keras.backend.clear_session()\n",
      "  File \"C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\keras\\backend.py\", line 279, in clear_session\n",
      "    tf.compat.v1.reset_default_graph()\n",
      "  File \"C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6200, in reset_default_graph\n",
      "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
      "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mjdom\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8320/3348357028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mstop_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m           **self.filter_sk_params(self.build_fn.__call__))\n\u001b[0;32m    154\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     if (losses.is_categorical_crossentropy(self.model.loss) and\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8320/2031994828.py\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(embed_dim, num_heads, ff_dim, dropout_rate)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#gc.collect()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mclear_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;32mglobal\u001b[0m \u001b[0m_GRAPH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m   \u001b[0m_GRAPH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m   \u001b[0mreset_uids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pipgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mreset_default_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m   6198\u001b[0m   \"\"\"\n\u001b[0;32m   6199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cleared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6200\u001b[1;33m     raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n\u001b[0m\u001b[0;32m   6201\u001b[0m                          \u001b[1;34m\"nested graphs. If you need a cleared graph, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m                          \"exit the nesting and create a new graph.\")\n",
      "\u001b[1;31mAssertionError\u001b[0m: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph."
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X, y)\n",
    "stop_time = time.time()\n",
    "\n",
    "# summarize results\n",
    "print('time search took:', stop_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638293143326,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "mHHBYBcV0Tcv",
    "outputId": "659fd5b8-63ac-4e50-b771-43fc199b74a5"
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638293143327,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "y-EYwhOg0bs4"
   },
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638293143327,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "SV2lVU3n0d_3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638293143327,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "7RhVj6Y20f5v"
   },
   "outputs": [],
   "source": [
    "d=pd.DataFrame(params)\n",
    "d['Mean']=means\n",
    "d['Std. Dev']=stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1638293144435,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "p-c1xuRg0gSf",
    "outputId": "c16e0339-54d9-49bc-c7ec-96ccbb10c308"
   },
   "outputs": [],
   "source": [
    "param_ = [\"num_heads\",\"ff_dim\",\"epochs\",\"embed_dim\",\"dropout_rate\"]\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,3,figsize=(14,8), squeeze=False)\n",
    "ax = ax.ravel()\n",
    "for i in range(5):\n",
    "    ax[i].set_title('Distribution of mean accuracy with {}'.format(param_[i]))\n",
    "    sns.violinplot(x=param_[i],y='Mean',data=d,ax=ax[i])\n",
    "fig.tight_layout(pad=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638293144435,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "ZiScCgY20kbP",
    "outputId": "86607ada-4429-46c0-87be-101f5386678e"
   },
   "outputs": [],
   "source": [
    "d.sort_values(by='Mean',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQv_EgX40mpY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1638293144599,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "l3tqZUpJ1ED5",
    "outputId": "51148e35-1107-4862-fb04-b22801bad3aa"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "len(stop)\n",
    "s_upper = []\n",
    "for s in stop:\n",
    "    s_upper.append(s[0].upper()+s[1:])\n",
    "\n",
    "all_stop = stop + s_upper\n",
    "\n",
    "len(all_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2119,
     "status": "ok",
     "timestamp": 1638293146717,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "D0vEVRDI1EIQ"
   },
   "outputs": [],
   "source": [
    "X_stop = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (all_stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638293147234,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "eAtb3Ou31KG5",
    "outputId": "cd834452-77fb-432f-d58c-a72cf598e807"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 15\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=64, verbose=0)\n",
    "# define the grid search parameters\n",
    "embed_dim = [32,64,128,256]\n",
    "num_heads = [1,2]\n",
    "ff_dim =  [32,64,128,256]\n",
    "dropout_rate = [0.0,0.1,0.2,0.3]\n",
    "epochs = [1,2]\n",
    "\n",
    "param_grid = dict(embed_dim=embed_dim,num_heads = num_heads,ff_dim = ff_dim,\n",
    "                  dropout_rate = dropout_rate, epochs=epochs)\n",
    "#grid = GridSearchCV(estimator=model, scoring = 'neg_log_loss', param_grid=param_grid, n_jobs=1, cv=3, verbose=3)\n",
    "grid = RandomizedSearchCV(model, param_grid, n_iter=100,scoring = 'neg_log_loss', n_jobs=1, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769140,
     "status": "ok",
     "timestamp": 1638293916371,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "5naB29gK1q6o",
    "outputId": "67c07d18-0f5e-4c6d-e97a-f82e36334e50"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "grid_result = grid.fit(X_stop, y)\n",
    "stop_time = time.time()\n",
    "\n",
    "# summarize results\n",
    "print('time search took:', stop_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638293916372,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "Leu5eZ-x1u_Q",
    "outputId": "e674ad43-6eeb-4fa5-da33-d7d3eb16d5ac"
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638293916372,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "m7oJkLXf1zNv"
   },
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638293916372,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "y6khOEvl13OP"
   },
   "outputs": [],
   "source": [
    "d=pd.DataFrame(params)\n",
    "d['Mean']=means\n",
    "d['Std. Dev']=stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1638293917503,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "wY320ROi13fH",
    "outputId": "9c56365e-17c3-43d3-95b1-920698baa6de"
   },
   "outputs": [],
   "source": [
    "param_ = [\"num_heads\",\"ff_dim\",\"epochs\",\"embed_dim\",\"dropout_rate\"]\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,3,figsize=(14,8), squeeze=False)\n",
    "ax = ax.ravel()\n",
    "for i in range(5):\n",
    "    ax[i].set_title('Distribution of mean accuracy with {}'.format(param_[i]))\n",
    "    sns.violinplot(x=param_[i],y='Mean',data=d,ax=ax[i])\n",
    "fig.tight_layout(pad=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638293917504,
     "user": {
      "displayName": "Michael Dominguez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14258183258878183412"
     },
     "user_tz": 300
    },
    "id": "Vj4LkRKC16e_",
    "outputId": "2b1b6a25-6785-498b-9693-adbca9221dee"
   },
   "outputs": [],
   "source": [
    "d.sort_values(by='Mean',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HreX-NJ17Cf"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def run_inference_or_training(X, y):\n",
    "    grid_result = grid.fit(X, y)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "p = multiprocessing.Process(\n",
    "    target=run_inference_or_training,\n",
    "    args=(X, y, )\n",
    ")\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current': 2304, 'peak': 232192}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8320/180091455.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "709750016/777168128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Process name='Process-4' pid=4276 parent=17948 started>\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import proc\n",
    "def run_inference_or_training2(X, y):\n",
    "    print(X,y)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "p = multiprocessing.Process(\n",
    "    target=proc.test2,\n",
    "    args=(2, 3, )\n",
    ")\n",
    "p.start()\n",
    "print(p)\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "if __name__ ==  '__main__': \n",
    "    num_processors = 1\n",
    "    p=Pool(processes = num_processors)\n",
    "    output = p.map(proc.test2,[(1),(2)])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Process(\n",
    "    target=proc.run_grid,\n",
    "    args=(X, y, grid)\n",
    ")\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMx7YsNhYLpAJQP/aG8jBO2",
   "collapsed_sections": [],
   "name": "tran_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
