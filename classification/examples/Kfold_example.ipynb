{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kfold_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVcv8kC5zeZl"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict,KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.svm import LinearSVC,SVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1mHTfKYzkCQ",
        "outputId": "7cf00b42-2420-4cdb-97fe-a178864ec1b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LjZV37Tkzlw3",
        "outputId": "a0747832-614e-44f8-fb8b-0f07d14fee6b"
      },
      "source": [
        "import os            ##  This module is for \"operating system\" interfaces\n",
        "import sys           ##  This module is for functionality relevant to the python run time\n",
        "\n",
        "GOOGLE_PATH_AFTER_MYDRIVE = 'NLP_Textcat/spooky_data/train'\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive','My Drive', GOOGLE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
        "\n",
        "# Append the directory path of this notebook to what python easily \"sees\"\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# Make your current working direct\n",
        "GOOGLE_DRIVE_PATH"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train.csv']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drive/My Drive/NLP_Textcat/spooky_data/train'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WSyHZuKxztdn",
        "outputId": "7ed5cccc-47aa-4205-d2fd-beff612bf8bd"
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/NLP_Textcat/spooky_data/train/train.csv')\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6T1l-4zv03"
      },
      "source": [
        "\n",
        "X = df[\"text\"].copy()\n",
        "#X = df[\"text\"]\n",
        "\n",
        "authors = df[\"author\"].copy()\n",
        "\n",
        "# Label data\n",
        "y = []\n",
        "for author in authors:\n",
        "    if author == \"EAP\":\n",
        "        y.append([1, 0, 0])\n",
        "    if author == \"HPL\":\n",
        "        y.append([0, 1, 0])\n",
        "    if author == \"MWS\":\n",
        "        y.append([0, 0, 1])\n",
        "\n",
        "y = np.array(y)\n",
        "\n",
        "y_one_vector = []\n",
        "for author in authors:\n",
        "    if author == \"EAP\":\n",
        "        y_one_vector.append(0)\n",
        "    if author == \"HPL\":\n",
        "        y_one_vector.append(1)\n",
        "    if author == \"MWS\":\n",
        "        y_one_vector.append(2)\n",
        "\n",
        "y_one_vector = np.array(y_one_vector)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpRuE6uizx5f"
      },
      "source": [
        "encoder = tf.keras.layers.TextVectorization()\n",
        "encoder.adapt(X)\n",
        "\n",
        "max_features = 1000000\n",
        "Vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode='tf_idf', ngrams=2)\n",
        "with tf.device('/device:CPU:0'):\n",
        "  Vectorizer.adapt(X)\n",
        "\n",
        "vocab = encoder.get_vocabulary()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbjP8zPxz3p3"
      },
      "source": [
        "class CNN1d(tf.keras.Model):\n",
        "    def __init__(self, conv1_filters, conv1_size, conv2_filters, conv2_size, dense1, encoder):\n",
        "        super(CNN1d, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "\n",
        "        vocab = encoder.get_vocabulary()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=len(vocab),output_dim=64,mask_zero=True)\n",
        "        \n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv1D(filters=conv1_filters,\n",
        "                            kernel_size=conv1_size,\n",
        "                            padding=\"same\",\n",
        "                            activation=\"relu\",\n",
        "                            data_format=\"channels_last\",\n",
        "                            )\n",
        "        self.conv2 = tf.keras.layers.Conv1D(filters=conv2_filters,\n",
        "                            kernel_size=conv2_size,\n",
        "                            padding=\"same\",\n",
        "                            activation=\"relu\",\n",
        "                            data_format=\"channels_last\",\n",
        "                            )\n",
        "        self.global_pool = tf.keras.layers.GlobalMaxPool1D(keepdims=False)\n",
        "        self.dense1 = tf.keras.layers.Dense(dense1, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(3, activation=\"softmax\")\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        emb = self.encoder(x)\n",
        "        emb = self.embedding(emb)\n",
        "        conv1 = self.conv1(emb)\n",
        "        conv2 = self.conv2(emb)\n",
        "        z = tf.concat([conv1, conv2], axis=2)\n",
        "        z = self.global_pool(z)\n",
        "        z = self.dense1(z)\n",
        "        z = self.dense2(z)\n",
        "        return z"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bob8Sjtbz5Mv"
      },
      "source": [
        "def create_model(conv1_filters, conv1_size, conv2_filters, conv2_size, dense1):\n",
        "    model = CNN1d(conv1_filters, conv1_size, conv2_filters, conv2_size, dense1, encoder)\n",
        "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_ngram():\n",
        "    model_ngram = tf.keras.Sequential()\n",
        "    model_ngram.add(Vectorizer)\n",
        "      \n",
        "    model_ngram.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "    model_ngram.add(tf.keras.layers.Dropout(0.2))\n",
        "      \n",
        "    model_ngram.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "      \n",
        "    model_ngram.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                metrics=['accuracy'])\n",
        "    return model_ngram\n",
        "\n",
        "def create_lstm():\n",
        "    LSTM = tf.keras.Sequential()\n",
        "    LSTM.add(encoder)\n",
        "    LSTM.add(tf.keras.layers.Embedding(input_dim=len(vocab),output_dim=64,mask_zero=True))\n",
        "      \n",
        "    LSTM.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,dropout=0.2,return_sequences=True)))\n",
        "    LSTM.add(tf.keras.layers.GlobalMaxPool1D())\n",
        "\n",
        "    LSTM.add(tf.keras.layers.Dropout(0.2))\n",
        "      \n",
        "    LSTM.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "      \n",
        "    LSTM.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                metrics=['accuracy'])\n",
        "    \n",
        "    return LSTM\n",
        "\n",
        "def create_ensemble():\n",
        "    ensemble = tf.keras.Sequential()\n",
        "    # for 3 model\n",
        "    ensemble.add(tf.keras.layers.Dense(36, activation='relu'))\n",
        "    ensemble.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    ensemble.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    #ensemble.add(tf.keras.layers.InputLayer())\n",
        "\n",
        "    ensemble.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return ensemble\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_sWe-F90tK8"
      },
      "source": [
        "max_features = 1000000\n",
        "tfidf_vec = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode='tf_idf', sparse=True, ngrams=2)\n",
        "\n",
        "with tf.device('/device:CPU:0'):\n",
        "  tfidf_vec.adapt(X)\n",
        "\n",
        "tdidf = tf.keras.Sequential([\n",
        "    tfidf_vec])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "kcnlddBUz7F_",
        "outputId": "9079769f-6772-4685-95aa-479bcf91d6b9"
      },
      "source": [
        "df = pd.DataFrame(columns = ['model', 'average', 'logloss'])\n",
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>average</th>\n",
              "      <th>logloss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [model, average, logloss]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XcAYPZIz-R_",
        "outputId": "f3caa729-2a33-4bd5-c095-7abb328a766e"
      },
      "source": [
        "kf = KFold(n_splits=10)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "  X_train = X.iloc[train_index]\n",
        "  X_test = X.iloc[test_index]\n",
        "  y_train = y[train_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "\n",
        "    \n",
        "  x_train_sparce = tdidf.predict(X_train)\n",
        "  x_test_sparce = tdidf.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  cnn = create_model(128, 6, 128, 5, 128)\n",
        "  ngram = create_ngram()\n",
        "  LSTM = create_lstm()\n",
        "  ensemble = create_ensemble()\n",
        "  ensemble_with_tdidf = create_ensemble()\n",
        "\n",
        "  cnn.fit(X_train, y_train, epochs=1 )\n",
        "\n",
        "  ngram.fit(X_train, y_train, epochs=1, batch_size=64)\n",
        "  \n",
        "  LSTM.fit(X_train, y_train, epochs=2, batch_size=64)\n",
        "  \n",
        "\n",
        "  cnn_pred = cnn.predict(X_train)\n",
        "  ngram_pred = ngram.predict(X_train)\n",
        "  LSTM_pred = LSTM.predict(X_train)\n",
        "\n",
        "  cnn_pred_test = cnn.predict(X_test)\n",
        "  ngram_pred_test = ngram.predict(X_test)\n",
        "  LSTM_pred_test = LSTM.predict(X_test)\n",
        "\n",
        "\n",
        "  X_train_ens = np.hstack([ngram_pred,cnn_pred,LSTM_pred])\n",
        "  X_test_ens = np.hstack([ngram_pred_test,cnn_pred_test,LSTM_pred_test])\n",
        "\n",
        "  X_train_final_tensor = tf.sparse.from_dense(X_train_ens)\n",
        "  X_test_final_tensor = tf.sparse.from_dense(X_test_ens)\n",
        "  X_train_concat_tensor = tf.sparse.concat(1,[x_train_sparce, X_train_final_tensor])\n",
        "  X_test_concat_tensor = tf.sparse.concat(1,[x_test_sparce, X_test_final_tensor])\n",
        "\n",
        "\n",
        "  ensemble.fit(X_train_ens, y_train, epochs=2, batch_size=128)\n",
        "  ensemble_with_tdidf.fit(X_train_concat_tensor, y_train, epochs=1, batch_size=256)\n",
        "\n",
        "  ngram_results = ngram.evaluate(X_test,y_test)\n",
        "  LSTM_results =LSTM.evaluate(X_test,y_test)\n",
        "  cnn_results =cnn.evaluate(X_test,y_test)\n",
        "  ensemble_results =ensemble.evaluate(X_test_ens,y_test)\n",
        "  ensemble_with_tdidf_results =ensemble_with_tdidf.evaluate(X_test_concat_tensor,y_test)\n",
        "\n",
        "\n",
        "\n",
        "  lin_reg = LinearRegression(fit_intercept=False, positive= True)\n",
        "  lin_reg.fit(X_train_ens, y_train)\n",
        "  linreg_logloss = log_loss(y_test,lin_reg.predict(X_test_ens))\n",
        "  linreg_acc = np.sum(np.argmax(y_test, axis = 1) == np.argmax(lin_reg.predict(X_test_ens), axis = 1))/len(np.argmax(y_test, axis = 1))\n",
        "\n",
        "\n",
        "  lin_reg2 = LinearRegression(fit_intercept=False, positive= True)\n",
        "  lin_reg2.fit(np.hstack((X_train_ens,ensemble_with_tdidf.predict(X_train_concat_tensor))), y_train)\n",
        "  linreg2_logloss = log_loss(y_test,lin_reg2.predict(np.hstack((X_test_ens,ensemble_with_tdidf.predict(X_test_concat_tensor)\n",
        "  ))))\n",
        "  linreg2_acc = np.sum(np.argmax(y_test, axis = 1) == np.argmax(lin_reg2.predict(np.hstack((X_test_ens,ensemble_with_tdidf.predict(X_test_concat_tensor)\n",
        "  ))), axis = 1))/len(np.argmax(y_test, axis = 1))\n",
        "\n",
        "\n",
        "  df_results = pd.DataFrame({\"model\":['ngram', 'cnn', 'LSTM','ensemble','ensemble_tdidf','lin_reg_1','lin_reg_2'],\\\n",
        "                  \"average\":[ngram_results[1],cnn_results[1],LSTM_results[1],ensemble_results[1],ensemble_with_tdidf_results[1],\\\n",
        "                             linreg_acc, linreg2_acc],\\\n",
        "                  \"logloss\":[ngram_results[0],cnn_results[0],LSTM_results[0],ensemble_results[0],ensemble_with_tdidf_results[0],\\\n",
        "                             linreg_logloss, linreg2_logloss]})\n",
        "\n",
        "  df = df.append(df_results)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "551/551 [==============================] - 32s 56ms/step - loss: 0.6802 - accuracy: 0.6915\n",
            "276/276 [==============================] - 31s 109ms/step - loss: 0.5440 - accuracy: 0.7808\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 66s 209ms/step - loss: 0.7617 - accuracy: 0.6550\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.3012 - accuracy: 0.8884\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.4811 - accuracy: 0.9103\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_7/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_7/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_7/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 8s 100ms/step - loss: 0.4478 - accuracy: 0.8435\n",
            "62/62 [==============================] - 2s 23ms/step - loss: 0.3647 - accuracy: 0.8616\n",
            "62/62 [==============================] - 4s 25ms/step - loss: 0.4390 - accuracy: 0.8315\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4375 - accuracy: 0.8264\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8667\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8687\n",
            "551/551 [==============================] - 31s 55ms/step - loss: 0.6729 - accuracy: 0.6955\n",
            "276/276 [==============================] - 30s 108ms/step - loss: 0.5421 - accuracy: 0.7794\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 66s 210ms/step - loss: 0.7436 - accuracy: 0.6676\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 57s 207ms/step - loss: 0.2901 - accuracy: 0.8934\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.8632\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 7s 98ms/step - loss: 0.4610 - accuracy: 0.8388\n",
            "62/62 [==============================] - 2s 24ms/step - loss: 0.3542 - accuracy: 0.8596\n",
            "62/62 [==============================] - 4s 28ms/step - loss: 0.4367 - accuracy: 0.8304\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4591 - accuracy: 0.8228\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8687\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8708\n",
            "551/551 [==============================] - 31s 53ms/step - loss: 0.6637 - accuracy: 0.7073\n",
            "276/276 [==============================] - 31s 110ms/step - loss: 0.5428 - accuracy: 0.7833\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 65s 201ms/step - loss: 0.7590 - accuracy: 0.6624\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 56s 204ms/step - loss: 0.3044 - accuracy: 0.8897\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.6324 - accuracy: 0.8142\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_12/dense_25/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_12/dense_25/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_12/dense_25/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 8s 102ms/step - loss: 0.4709 - accuracy: 0.8425\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.3690 - accuracy: 0.8514\n",
            "62/62 [==============================] - 5s 32ms/step - loss: 0.4412 - accuracy: 0.8304\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.4458 - accuracy: 0.8192\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8570\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8682\n",
            "551/551 [==============================] - 31s 55ms/step - loss: 0.6705 - accuracy: 0.7024\n",
            "276/276 [==============================] - 30s 108ms/step - loss: 0.5511 - accuracy: 0.7805\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 67s 211ms/step - loss: 0.7783 - accuracy: 0.6475\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 58s 210ms/step - loss: 0.3064 - accuracy: 0.8875\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.4741 - accuracy: 0.9450\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_16/dense_34/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_16/dense_34/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_16/dense_34/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 7s 98ms/step - loss: 0.4840 - accuracy: 0.8404\n",
            "62/62 [==============================] - 2s 24ms/step - loss: 0.3754 - accuracy: 0.8498\n",
            "62/62 [==============================] - 4s 25ms/step - loss: 0.4342 - accuracy: 0.8361\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4282 - accuracy: 0.8269\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8652\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8672\n",
            "551/551 [==============================] - 30s 53ms/step - loss: 0.6586 - accuracy: 0.7096\n",
            "276/276 [==============================] - 30s 108ms/step - loss: 0.5509 - accuracy: 0.7805\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 66s 207ms/step - loss: 0.7383 - accuracy: 0.6700\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 57s 206ms/step - loss: 0.2905 - accuracy: 0.8943\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.5621 - accuracy: 0.8885\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_20/dense_43/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_20/dense_43/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_20/dense_43/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 7s 99ms/step - loss: 0.4543 - accuracy: 0.8460\n",
            "62/62 [==============================] - 2s 24ms/step - loss: 0.3558 - accuracy: 0.8682\n",
            "62/62 [==============================] - 4s 28ms/step - loss: 0.3839 - accuracy: 0.8422\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4072 - accuracy: 0.8427\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8784\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8805\n",
            "551/551 [==============================] - 30s 53ms/step - loss: 0.6737 - accuracy: 0.6978\n",
            "276/276 [==============================] - 30s 107ms/step - loss: 0.5378 - accuracy: 0.7873\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 67s 211ms/step - loss: 0.7685 - accuracy: 0.6497\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 58s 211ms/step - loss: 0.3044 - accuracy: 0.8909\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.8694\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_24/dense_52/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_24/dense_52/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_24/dense_52/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 7s 99ms/step - loss: 0.4404 - accuracy: 0.8493\n",
            "62/62 [==============================] - 2s 23ms/step - loss: 0.3774 - accuracy: 0.8509\n",
            "62/62 [==============================] - 4s 29ms/step - loss: 0.4429 - accuracy: 0.8309\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4492 - accuracy: 0.8172\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8590\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8652\n",
            "551/551 [==============================] - 31s 54ms/step - loss: 0.6653 - accuracy: 0.7065\n",
            "276/276 [==============================] - 30s 107ms/step - loss: 0.5399 - accuracy: 0.7847\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 66s 209ms/step - loss: 0.7442 - accuracy: 0.6699\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 57s 208ms/step - loss: 0.2873 - accuracy: 0.8955\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.8237\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_28/dense_61/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_28/dense_61/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_28/dense_61/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 7s 98ms/step - loss: 0.4480 - accuracy: 0.8475\n",
            "62/62 [==============================] - 2s 23ms/step - loss: 0.3776 - accuracy: 0.8483\n",
            "62/62 [==============================] - 4s 29ms/step - loss: 0.4000 - accuracy: 0.8483\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4547 - accuracy: 0.8248\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8682\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8718\n",
            "551/551 [==============================] - 30s 53ms/step - loss: 0.6652 - accuracy: 0.6956\n",
            "276/276 [==============================] - 30s 108ms/step - loss: 0.5545 - accuracy: 0.7796\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 67s 213ms/step - loss: 0.7491 - accuracy: 0.6666\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 58s 212ms/step - loss: 0.2940 - accuracy: 0.8939\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.8721\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_32/dense_70/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_32/dense_70/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_32/dense_70/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 8s 99ms/step - loss: 0.4583 - accuracy: 0.8503\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.3710 - accuracy: 0.8585\n",
            "62/62 [==============================] - 5s 29ms/step - loss: 0.4684 - accuracy: 0.8284\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4441 - accuracy: 0.8223\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.8590\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8703\n",
            "551/551 [==============================] - 31s 54ms/step - loss: 0.6738 - accuracy: 0.7014\n",
            "276/276 [==============================] - 31s 109ms/step - loss: 0.5277 - accuracy: 0.7912\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 66s 213ms/step - loss: 0.7463 - accuracy: 0.6611\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 59s 212ms/step - loss: 0.2818 - accuracy: 0.8957\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.8701\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_36/dense_79/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_36/dense_79/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_36/dense_79/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 8s 99ms/step - loss: 0.4468 - accuracy: 0.8482\n",
            "62/62 [==============================] - 2s 24ms/step - loss: 0.3618 - accuracy: 0.8641\n",
            "62/62 [==============================] - 4s 26ms/step - loss: 0.4230 - accuracy: 0.8376\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4360 - accuracy: 0.8248\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8677\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8713\n",
            "551/551 [==============================] - 30s 54ms/step - loss: 0.6651 - accuracy: 0.6999\n",
            "276/276 [==============================] - 31s 109ms/step - loss: 0.5343 - accuracy: 0.7822\n",
            "Epoch 1/2\n",
            "276/276 [==============================] - 68s 213ms/step - loss: 0.7518 - accuracy: 0.6646\n",
            "Epoch 2/2\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.3041 - accuracy: 0.8880\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 1s 2ms/step - loss: 0.6230 - accuracy: 0.8353\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_40/dense_88/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_40/dense_88/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_40/dense_88/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 8s 101ms/step - loss: 0.4528 - accuracy: 0.8455\n",
            "62/62 [==============================] - 2s 24ms/step - loss: 0.3855 - accuracy: 0.8523\n",
            "62/62 [==============================] - 5s 28ms/step - loss: 0.4153 - accuracy: 0.8426\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4312 - accuracy: 0.8304\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8682\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "G7R3Undi0nDH",
        "outputId": "f4a811b8-115a-482d-ce6b-6cb751bb8de5"
      },
      "source": [
        "df.groupby('model').describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">average</th>\n",
              "      <th colspan=\"8\" halign=\"left\">logloss</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.835845</td>\n",
              "      <td>0.006681</td>\n",
              "      <td>0.828396</td>\n",
              "      <td>0.830567</td>\n",
              "      <td>0.833759</td>\n",
              "      <td>0.841037</td>\n",
              "      <td>0.848315</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.428474</td>\n",
              "      <td>0.023969</td>\n",
              "      <td>0.383926</td>\n",
              "      <td>0.417268</td>\n",
              "      <td>0.435471</td>\n",
              "      <td>0.440643</td>\n",
              "      <td>0.468366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cnn</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.825732</td>\n",
              "      <td>0.007066</td>\n",
              "      <td>0.817160</td>\n",
              "      <td>0.822395</td>\n",
              "      <td>0.824821</td>\n",
              "      <td>0.826736</td>\n",
              "      <td>0.842697</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.439301</td>\n",
              "      <td>0.014993</td>\n",
              "      <td>0.407225</td>\n",
              "      <td>0.432396</td>\n",
              "      <td>0.440789</td>\n",
              "      <td>0.448356</td>\n",
              "      <td>0.459085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.865826</td>\n",
              "      <td>0.006271</td>\n",
              "      <td>0.856997</td>\n",
              "      <td>0.860572</td>\n",
              "      <td>0.867211</td>\n",
              "      <td>0.868216</td>\n",
              "      <td>0.878447</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.367114</td>\n",
              "      <td>0.012986</td>\n",
              "      <td>0.347134</td>\n",
              "      <td>0.357811</td>\n",
              "      <td>0.365570</td>\n",
              "      <td>0.378712</td>\n",
              "      <td>0.385331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_tdidf</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.869860</td>\n",
              "      <td>0.004480</td>\n",
              "      <td>0.864589</td>\n",
              "      <td>0.867467</td>\n",
              "      <td>0.869510</td>\n",
              "      <td>0.871170</td>\n",
              "      <td>0.880490</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.342707</td>\n",
              "      <td>0.011954</td>\n",
              "      <td>0.317080</td>\n",
              "      <td>0.336713</td>\n",
              "      <td>0.344938</td>\n",
              "      <td>0.348617</td>\n",
              "      <td>0.359730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lin_reg_1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.856938</td>\n",
              "      <td>0.006826</td>\n",
              "      <td>0.848825</td>\n",
              "      <td>0.851232</td>\n",
              "      <td>0.855465</td>\n",
              "      <td>0.861593</td>\n",
              "      <td>0.868744</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.368506</td>\n",
              "      <td>0.010078</td>\n",
              "      <td>0.353872</td>\n",
              "      <td>0.362458</td>\n",
              "      <td>0.368880</td>\n",
              "      <td>0.376489</td>\n",
              "      <td>0.384315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lin_reg_2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.870167</td>\n",
              "      <td>0.004518</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.868999</td>\n",
              "      <td>0.869765</td>\n",
              "      <td>0.871170</td>\n",
              "      <td>0.880490</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.338839</td>\n",
              "      <td>0.010939</td>\n",
              "      <td>0.316604</td>\n",
              "      <td>0.332199</td>\n",
              "      <td>0.341282</td>\n",
              "      <td>0.343294</td>\n",
              "      <td>0.355336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ngram</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.856479</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.848315</td>\n",
              "      <td>0.850996</td>\n",
              "      <td>0.855427</td>\n",
              "      <td>0.861083</td>\n",
              "      <td>0.868233</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.369239</td>\n",
              "      <td>0.010141</td>\n",
              "      <td>0.354201</td>\n",
              "      <td>0.362509</td>\n",
              "      <td>0.370010</td>\n",
              "      <td>0.376938</td>\n",
              "      <td>0.385483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               average                      ...   logloss                    \n",
              "                 count      mean       std  ...       50%       75%       max\n",
              "model                                       ...                              \n",
              "LSTM              10.0  0.835845  0.006681  ...  0.435471  0.440643  0.468366\n",
              "cnn               10.0  0.825732  0.007066  ...  0.440789  0.448356  0.459085\n",
              "ensemble          10.0  0.865826  0.006271  ...  0.365570  0.378712  0.385331\n",
              "ensemble_tdidf    10.0  0.869860  0.004480  ...  0.344938  0.348617  0.359730\n",
              "lin_reg_1         10.0  0.856938  0.006826  ...  0.368880  0.376489  0.384315\n",
              "lin_reg_2         10.0  0.870167  0.004518  ...  0.341282  0.343294  0.355336\n",
              "ngram             10.0  0.856479  0.006849  ...  0.370010  0.376938  0.385483\n",
              "\n",
              "[7 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "EtGHRot31vIf",
        "outputId": "4ffbdbbe-cbfc-4258-dfc5-58df71fae6a7"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "df.boxplot('average',by = 'model', ax=ax[0])\n",
        "df.boxplot('logloss',by = 'model', ax=ax[1])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKsAAAFZCAYAAABXHKw9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZxdZXno/d/FBARDCLbYVF7Dqfg5E4MiRpDHWAcRGqUVra0y+EY7bfRUcqxayviEByM6bdACpccc22goKRwHOPblSU0MPGKmNh71gC+oyRyPkbcEeAoIRQZ5ScJ1/thrcDNMMivMmtlr9v59P5/5sPda97rXta5ZCTvXvtd9R2YiSZIkSZIk1cF+rQ5AkiRJkiRJGmWxSpIkSZIkSbVhsUqSJEmSJEm1YbFKkiRJkiRJtWGxSpIkSZIkSbVhsUqSJEmSJEm1YbFKkiTNeBGREfHiVsfRShHRExE79rK/9jmKiPlFnLNKtD03IjZPR1ySJGl6WaySJEmViYg7IuKxiBiJiIciYn1EHNXquEZZ4JAkSao/i1WSJKlqv5WZBwMvAv4N+C8tjmfKlBkBJEmSpH1jsUqSJE2JzHwc+CKwYHRbRMyNiL+LiPsj4s6IuDAi9ouIX4qIHRHxW0W7gyNiW0S8p3h/VUT8dUT8fxHxSET8S0QcM95593KObuCvgVOKkV//vofjj42IrxXn+UpErIqIa4p9o4+p9UXEXcBXi74vLM51X3HuuUX7Zz2aV4w+e0PxekVEfDEirivO952IeHlT28Mj4u+La7k9Iv5z076Dirw8FBFbgVeV+LW8KSJui4gHIuLTRewHRMSDEXF8U9+/EhE/j4gXjpOfcyPi6xFxeUT8e9Hf/1Vs317k4L0T/T6KfV0R8RdFPLcBZ47zu1wTEfdGxN0R8cmI6CpxnZIkaQazWCVJkqZERDwfeAfwzabN/wWYC/wH4HXAe4Dfy8wHgd8HPhcRvwJcDnwvM/+u6dh3Ap8ADgO+B/y3PZx6T+cYBt4PfCMzD87MQ/dw/BeA/wn8MrACePc4bV4HdAO/AZxb/JxanPNg4DN76Hs8ZwH/Hfil4tz/FBH7FwWdfwZuBY4ATgP+OCJ+ozjuY8CvFT+/Abx3bMfjeCuwCDixOO/vZ+aTwLXAu5ra9QI3Zeb9e+jnZOD7NHL0heL4VwEvLvr5TEQcXLQd9/dR7PtD4DeBVxRx/c6Y81wF7Cr6fQVwBvAHJa5TkiTNYBarJElS1f6pGLX0MHA68GlojKIBzgY+mpmPZOYdwKUUxaDMvJFG0eYm4E3A+8b0uz4zv5aZTwDLaYyQesZ8WBOdYyIRcTSNostFmflkZm4G1o3TdEVmPpqZj9Eool2Wmbdl5gjwUeDsfXhE8NuZ+cXM3AlcBhwIvLqI44WZeXERy23A54rrA3g7MJCZD2bmduCvSpzrkqL9XcBf0ihKAawFeiMiivfvBq7eSz+3Z+bfZuZu4DrgKODizHyi+D0+Cby4xO/j7cBfZub2omD556MniIh5NO6DPy5yfR+NIubo9UuSpDblPAuSJKlqb8nMrxSFirOAf4mIBUAC+wN3NrW9k8aooVGrgfOAP8vMn47pd/voi8wciYgHgcObt9MYdTXROfbmcODBzPz5mPOOnSS++ZyHj3O+WcC8kudsvq6niscGD6eRr8PHPK7YBfxr03mb42iOYcJzFe0PL877rYj4OdATEffSGMk0XpFu1L81vX6s6GPstoOZ+Pext2s4pjj23l/U0NhvTHtJktSGHFklSZKmRGbuzsx/AHYDi4EHgJ00ihCjjgbuhqdHRa0G/g74o4h48Zguny4YFY+Y/RJwz5g2ez0HjQLQ3twL/FLxCOOzztt8eU2v7xnnfLtoFHQeBZ7uq7jGsfNANV/XfsCRRZ/baYxgOrTpZ05mvqkp1ubYjp7g2sZey9E8M39raTzC927gi8WcY5M10e9jb9ewHXgCOKzp+g/JzJdWEJckSaoxi1WSJGlKRMNZwAuA4eKRseuBgYiYU0yQ/mHgmuKQ/5tGEej3aTw6+HdjJtN+U0QsjogDaMxd9c3i8benlTjHvwFHFn08S2beCdwCrCgmHj8F+K0JLnUQ+FAxMfvBwJ8B12XmLuB/AwdGxJkRsT9wIfC8Mce/MiJ+u3hs8I9pFGi+SWPerEci4oJiMvWuiFgYEaMTqV8PfDQiXhARRwLLJogT4Pyi/VHAB2k8wjfqGhpzWr2LRsFw0kr8Pq4H/nNEHBkRLwD6m469F7gRuDQiDikmg/+1iHhdFbFJkqT6slglSZKq9s8RMQL8DBgA3puZW4p9y2iMNroN2Exjcu4rI+KVNIoY7ykKHJfQKFz1N/X7BRqTij8IvJJnTgjebNxzFPu+CmwB/v+IeGAPx78TOAX4KfBJGgWdJ/ZyvVfSmN/pa8DtwONFDGTmw8AfAZ+nMZroUWDHmOP/XxoT0T9EY1TTb2fmziIPvwmcUPT7QNHP3OK4j9N4bO52GkWdvc0x1Xyub9OYoH49sGZ0R1H4+w6NvP/ruEc/N3v7fXwOuIHGJPLfAf5hzLHvAQ4AttLIzxeBF1UYmyRJqqHInGg0vCRJUmtFxFXAjsy8sAXnvg74X5n5sSnoewXw4szcU+FtWkXElcA9rcizJEnSKCdYlyRJalI8ZvcgjRFLZ9CYJH5lS4OaBhExH/ht4BWtjUSSJHU6HwOUJEl6pl8FhoAR4K+A/5SZ321pRFMsIj4B/BD4dGbe3up4JElSZ/MxQEmSJEnSs0TEHcAfZOZXJtHHVbToMW5JM5cjqyRJkiRJklQbFqskzQjFku6SJEmSpDZnsUpSJSKiPyJ+EhGPRMTWiHhrRDwvIv49IhY2tXthRDwWEb9SvP/NiPhe0e5/RMTLmtreEREXRMT3gUcjYtZ452lq3xURl0bEAxFxe0ScFxE5WuiKiLkRsSYi7o2IuyPikxHRNY1pkiRJmnGKz3R/GRH3FD9/GRHPa9r/p8Xnq3si4g+Kz18v3kNffxgR2yLiwYhYFxGHF9sjIi6PiPsi4mcR8YPRz5AR8abic98jxWe4P5meK5fUKharJFXlJ8BrgbnAx4FrgF8C/gHobWr3duBfMvO+iHgFcCXwPuCXgb8B1jV/+CmOPRM4NDN3jXeeiHhR0fYPgTcCJwAnAm8ZE+NVwC7gxTRWuzoD+IPJXrgkSVKbWw68msZnrJcDJwEXAkTEEuDDwBtofMbq2VMnEfF64M9pfB58EXAncG2x+wzg14GX0Pic93bgp8W+NcD7MnMOsBD4amVXJqmWLFZJqkRm/vfMvCczn8rM64Af0/gg8wXg7Kam5xTbAJYCf5OZ38rM3Zm5FniCxoehUX+Vmdsz87EJzgONDzVXZOaOzHyIpqXmI2Ie8CbgjzPz0cy8D7h8TGySJEl6tncCF2fmfZl5P40vDN9d7Hs78LeZuSUzfw6smKCfKzPzO5n5BPBR4JSImA/sBOYA/5HGQmDDmXlvcdxOYEFEHJKZD2Xmdyq+Pkk1Y7FKUiUi4j1Nj/P9O41vvQ4DNgHPj4iTiw8iJwD/WBx2DPCR0WOK444CDm/qenvJ81Act30Pxx4D7A/c23Ts3wC/MumLlyRJam+H0xgFNepOfvF5bW+fv/baT2aO0Bg9dURmfhX4DLAKuC8iVkfEIUXTt9H40vHOiPiXiDhlMhcjqf4sVkmatIg4BvgccB7wy5l5KPBDGt+K7Qaup/E4Xy/wpcx8pDh0OzCQmYc2/Tw/Mwebus8y5yma3Asc2XTsUU2vt9MYtXVY07kOycyXVpIESZKk9nUPjS/+Rh1dbIO9f/7aaz8RMZvGVBB3A2TmX2XmK4EFNB4HPL/YfnNmnkXjS8Z/ovHZUlIbs1glqQqzaRSV7geIiN+jMeJp1BeAd9AY+v2Fpu2fA95fjLqKiJgdEWdGxJzneJ7rgQ9GxBERcShwweiOYhj5jcClEXFIROwXEb8WEa977pctSZLUEQaBC4uFcg4DLqIxPyk0Pn/9XkR0R8Tzgf9ngn5+LyJOKOYo/TPgW5l5R0S8qvhMuD/wKPA48FREHBAR74yIuZm5E/gZ8NQUXaekmrBYJWnSMnMrcCnwDeDfgOOBrzft/xaNDx2HA19u2n4LjUnRPwM8BGwDzn2u56FR/LoR+D7wXWADjQnVdxf73wMcAGwtzvdFGpN7SpIkac8+CdxC4zPWD4DvFNvIzC8Df0Vj6odtwDeLY54Y20lmfoVGMevvaYzI+jV+MX/oITQ+yz1E41HBnwKfLva9G7gjIn4GvJ/GF6CS2lhk5sStJGkGiog3An+dmcdM2FiSJEmTFhHdNKZpeF6xkrMk7TNHVklqGxFxUES8KSJmRcQRwMf4xWTukiRJmgIR8daIeF5EvAC4BPhnC1WSJsNilaR2EjSWUn6IxmOAwzTmVJAkSdLUeR9wH/ATGtMv/KfWhiNppvMxQEmSJEmSJNWGI6skSZIkSZJUGxarJEmSJEmSVBuzWh3AWIcddljOnz+/1WE8y6OPPsrs2bNbHcaMYK7KMU/lmavyzFV55qq8Oubq29/+9gOZ+cJWx6E9q+Nnujrey3VlrsozV+WZq3LMU3nmqrw65mpvn+dqV6yaP38+t9xyS6vDeJahoSF6enpaHcaMYK7KMU/lmavyzFV55qq8OuYqIu5sdQzauzp+pqvjvVxX5qo8c1WeuSrHPJVnrsqrY6729nnOxwAlSZIkSZJUGxarJEmSJEmSVBsWqyRJkiRJklQbFqskSZIkSZJUGxarJEmSJEmSVBsWqyRJkiRJklQbFqskSZIkSZJUGxarJNXW4OAgCxcu5LTTTmPhwoUMDg62OiS1Ae8rSZIkqd5mlWkUEUuAK4Au4POZuXLM/qOBtcChRZv+zNwQEfsDnwdOLM71d5n55xXGL6lNDQ4Osnz5ctasWcPu3bvp6uqir68PgN7e3hZHp5nK+0qSJEmqvwlHVkVEF7AKeCOwAOiNiAVjml0IXJ+ZrwDOBv5rsf13gedl5vHAK4H3RcT8akKX1M4GBgZYs2YNp556KrNmzeLUU09lzZo1DAwMtDo0zWDeV5IkSVL9lRlZdRKwLTNvA4iIa4GzgK1NbRI4pHg9F7inafvsiJgFHAQ8Cfysgrgltbnh4WEWL178jG2LFy9meHi4RRGpHXhfSe0rIirrKzMr60uSJO27MnNWHQFsb3q/o9jWbAXwrojYAWwAlhXbvwg8CtwL3AX8RWY+OJmAJXWG7u5uNm/e/Ixtmzdvpru7u0URqR14X0ntKzMn/Dnmgi+VaidJklqr1JxVJfQCV2XmpRFxCnB1RCykMSprN3A48ALgXyPiK6OjtEZFxFJgKcC8efMYGhqqKKzqjIyM1DKuOjJX5ZinvXvrW9/KO9/5Ts4//3yOPfZYLr/8cj796U/T19dn3vbC+2rvvK+eG+8rSZIkTacyxaq7gaOa3h9ZbGvWBywByMxvRMSBwGHAOcDGzNwJ3BcRXwcWAc8oVmXmamA1wKJFi7Knp2ffr2SKDQ0NUce46shclWOe9q6np4cFCxYwMDDA8PAw3d3dXHrppU6CPQHvq73zvnpuvK8kSZI0nco8BngzcFxEHBsRB9CYQH3dmDZ3AacBREQ3cCBwf7H99cX22cCrgf9VTeiS2l1vby8//OEPuemmm/jhD39oQUGV8L6SJEmS6m3CYlVm7gLOA24Ahmms+rclIi6OiDcXzT4C/GFE3AoMAudm44H/VcDBEbGFRtHrbzPz+1NxIZIkSZIkSZr5Ss1ZlZkbaEyc3rztoqbXW4HXjHPcCPC7k4xRkiRJkiRJHaLMY4CSJEmSJEnStKhqNUBJTSKi0v5cRluSJEmS1CkcWSVNgcyc8OeYC75Uqp2FKkmSJElSJ7FYJUmS1AEiYklE/CgitkVE/17avS0iMiIWNW17WUR8IyK2RMQPIuLA6YlakiR1Ih8DlCRJanMR0UVjlebTgR3AzRGxrlgkp7ndHOCDwLeats0CrgHenZm3RsQvAzunLXhJktRxHFklSZLU/k4CtmXmbZn5JHAtcNY47T4BXAI83rTtDOD7mXkrQGb+NDN3T3XAkiSpc1mskiRJan9HANub3u8otj0tIk4EjsrM9WOOfQmQEXFDRHwnIv50akOVJEmdzscAJUmSOlxE7AdcBpw7zu5ZwGLgVcDPgZsi4tuZedM4/SwFlgLMmzePoaGhqQr5OatjTHU0MjJirkoyV+WZq3LMU3nmqryZliuLVZIkSe3vbuCopvdHFttGzQEWAkMRAfCrwLqIeDONUVhfy8wHACJiA3Ai8KxiVWauBlYDLFq0KHt6eiq/kEnZuJ7axdQCxe+4Eq5a3CiAel+VY67KMU/lmavyZlqufAxQkiSp/d0MHBcRx0bEAcDZwLrRnZn5cGYelpnzM3M+8E3gzZl5C3ADcHxEPL+YbP11wNZnn0IzRWZO+HPMBV8q1U6SpKlgsUqSJKnNZeYu4Dwahadh4PrM3BIRFxejp/Z27EM0HhG8Gfge8J1x5rWSJEmqjI8BSpIkdYDM3ABsGLPtoj207Rnz/hrgmikLTpIkqYkjqyRJkiRJklQbFqskSZIkSZJUGxarJEmSJEmSVBsWqyRJkiRJklQbFqskSZIkSZJUGxarJEmSJEmSVBsWqyRJkiRJklQbFqskSZIkSZJUGxarJEmSJEmSVBsWqyRJkiRJklQbFqskSZIkSZJUGxarJEmSJEmSVBsWqyRJkiRJklQbs1odgCRJVYqISvvLzEr7kyRJkrR3FqskSW2lbHFpfv967lh55hRHI0nT5+Ufv5GHH9tZWX/z+9dX0s/cg/bn1o+dUUlfkqTOYLFKUktVOQrGETCSpE728GM7KyvCDw0N0dPTU0lfVRW9JEmdwzmrJLVUZk74c8wFXyrVTpIkSZI08zmyStKU8FEETYU63lfeU5IkSVK1ShWrImIJcAXQBXw+M1eO2X80sBY4tGjTn5kbIuKdwPlNTV8GnJiZ36sieEn15aMImgp1vK+8pyRJkqRqTfgYYER0AauANwILgN6IWDCm2YXA9Zn5CuBs4L8CZOZ/y8wTMvME4N3A7RaqJEmSJEmStCdl5qw6CdiWmbdl5pPAtcBZY9okcEjxei5wzzj99BbHSpIkSZIkSeMq8xjgEcD2pvc7gJPHtFkB3BgRy4DZwBvG6ecdPLvIJUmSJEmSJD2tqgnWe4GrMvPSiDgFuDoiFmbmUwARcTLw88z84XgHR8RSYCnAvHnzGBoaqiis6oyMjNQyrjoyV+W1e56qur6q76l2znsn/Pmr433V7jnvhPtKkiRJ9VGmWHU3cFTT+yOLbc36gCUAmfmNiDgQOAy4r9h/NjC4pxNk5mpgNcCiRYuyqomUq1TlBM/tzlyVtHF9e+epwuur9J5q87y3+5+/OXcez7I7K+zwp5PvYk439PT8YPId1Vi731edYqIFc5ravQ34IvCqzLylafvRwFZgRWb+xTSELEmSOlSZYtXNwHERcSyNItXZwDlj2twFnAZcFRHdwIHA/QARsR/wduC1VQUtqf7mdPdz/Nr+6jpcW003c7oBqllNTtPvkeGVrgYoPQdNC+acTmNKh5sjYl1mbh3Tbg7wQeBb43RzGfDlqY5VkiRpwmJVZu6KiPOAG2h8E3dlZm6JiIuBWzJzHfAR4HMR8SEak62fm5lZdPHrwPbMvG1qLkFSHdWxqAAWFiR1rKcXzAGIiNEFc7aOafcJ4BLg/OaNEfEW4Hbg0akPVZIkdbpSc1Zl5gZgw5htFzW93gq8Zg/HDgGvfu4hSpL0C5UWHDdOvq+5B+1fQSDSlJtwwZyIOBE4KjPXR8T5TdsPBi6gMSrrT6Yh1md4+cdv5OHHdlbWX1V/h8w9aH9u/dgZlfRVFUc1S5LaRVUTrEuSplhEVNbXLwa/zixlRutVmSeYubmS9kUxbcNlwLnj7F4BXJ6ZIxP9+ZqKRXMefmwnVy2ZPel+oLFYwMEHH1xJX+dufLR2Cw88MrzSXLWAi1CUZ67KMU/lmavyZlquLFZJ0gxRpmgyv399ZY9fzlRli0tOGq4OM9GCOXOAhcBQUZD6VWBdRLyZxgis34mITwGHAk9FxOOZ+ZmxJ5mSRXNcsKM8c9US/v+kPHNVjnkqz1yVN9NyZbFK2kdVPo7Qzo8iSKo/R6F1lL0umJOZD9NYyRmAiBgC/qRYDfC1TdtXACPjFaokSZKqYrFK2kcPP7azkpErThouqdXKFpccsTfzlVwwR5IkqRYsVkmSJHWAiRbMGbO9Zw/bV1QemCRJ0hgWqyRNmbqt2gau3CZJkiRJdWexStpHlS4L3cZLQlf5yJCPIEmSJElS57BYJe2jR4ZXOmeVJEnTpNIviaCtvyiSJKldWKySJElSbVX1JRH4RZEkSTPFfq0OQJIkSZIkSRplsUqSJEmSJEm1YbFKktRRBgcHWbhwIaeddhoLFy5kcHCw1SFJkiRJauKcVZKkjjE4OMjy5ctZs2YNu3fvpquri76+PgB6e3tbHJ0kTV6lc2ltrKavuQftX0k/kqTOYbFKktQxBgYGWLNmDaeeeurTEy2vWbOGZcuWWaySNONVNRE9NIpeVfYnSdK+8DFASVLHGB4eZvHixc/YtnjxYoaHh1sUkSRJkqSxLFZJkjpGd3c3mzdvfsa2zZs3093d3aKIJEmSJI3lY4CSWioiyrW7ZOI2mTnJaNTuli9fzjve8Q5mz57NnXfeyTHHHMOjjz7KFVdc0erQJEmSJBUcWSWppTJzwp9NmzaVaifti7KFUkmSJEnTy2KVJKljDAwMcN1113H77bdz0003cfvtt3PdddcxMDDQ6tAkSZIkFXwMUJLUMZxgXZJ8BF+SVH+OrJIkdQwnWJckH8GXJNWfxSpJUsdYvnw5fX19bNq0iV27drFp0yb6+vpYvnx5q0OTJEmSVPAxQElSx+jt7QVg2bJlDA8P093dzcDAwNPbJUmSJLWexSpJUkfp7e2lt7eXoaEhenp6Wh2OJEmSpDF8DFCSJEmSJEm1YbFKkiRJkiRJtWGxSpIkSZIkSbXhnFWS1GIv//iNPPzYzsr6m9+/vpJ+5h60P7d+7IxK+pIkSZKksixWSVKLPfzYTu5YeWYlfVU5aXhVRS9J9RARS4ArgC7g85m5cg/t3gZ8EXhVZt4SEacDK4EDgCeB8zPzq9MUtiRJ6kAWqyRJakN1HLHnaL3WiYguYBVwOrADuDki1mXm1jHt5gAfBL7VtPkB4Lcy856IWAjcABwxPZFLkqROVKpYNdE3cRFxNLAWOLRo05+ZG4p9LwP+BjgEeIrGt3SPV3YFkiTpWeo4Ys/Rei11ErAtM28DiIhrgbOArWPafQK4BDh/dENmfrdp/xbgoIh4XmY+MbUhS5KkTjVhsarkN3EXAtdn5mcjYgGwAZgfEbOAa4B3Z+atEfHLQHVf80otUtk/uDZWN7eQJEl7cQSwven9DuDk5gYRcSJwVGauj4jzGd/bgO9YqJIkSVOpzMiqMt/EJY2RUwBzgXuK12cA38/MWwEy86dVBC21UlUjFeb3r6+sL0mSJiMi9gMuA87dS5uX0hh1tcdnOSNiKbAUYN68eQwNDVUSX1X9jIyMVNYXVBdXHVWdq3ZmrsozV+WYp/LMVXkzLVdlilUTfhMHrABujIhlwGzgDcX2lwAZETcALwSuzcxPTSpiSZIk7au7gaOa3h9ZbBs1B1gIDEUEwK8C6yLizcUk60cC/wi8JzN/sqeTZOZqYDXAokWLspIFHzaur2zhiCoXoagyrjqqNFdtzlyVZ67KMU/lmavyZlquqppgvRe4KjMvjYhTgKuLCThnAYuBVwE/B26KiG9n5k3NB0/Vt3BVmmlVyFYyV+WZp3I64Z5y1MD0874qr8pctXvOa+xm4LiIOJZGkeps4JzRnZn5MHDY6PuIGAL+pChUHQqspzEn6denNWpJktSRyhSrJvomDqAPWAKQmd+IiANpfODZAXwtMx8AiIgNwInAM4pVU/ItXMVmWhWylcxVSW3+jWyV2v6ectRAS3hflVdZrtr8nqqzzNwVEefRWMmvC7gyM7dExMXALZm5bi+Hnwe8GLgoIi4qtp2RmfdNbdSSJKlTlSlW7fWbuMJdwGnAVRHRDRwI3E/jA9GfRsTzgSeB1wGXVxS7JEmSSipWat4wZttFe2jb0/T6k8AnpzQ4SZKkJhMWq0p+E/cR4HMR8SEak62fm5kJPBQRl9EoeCWwITNdt1qSJEmlVbYKL7gSryRJM0CpOasm+iYuM7cCr9nDsdcA10wiRkmSJHWoKlfOdSVeSZJmhv1aHYAkSZIkSZI0ymKVJEmSJEmSasNilSRJkiRJkmrDYpUkSZIkSZJqw2KVJEmSJEmSasNilSRJkiRJkmpjVqsDkNpRRJRrd0m5/jJzEtFIkiRJkjRzOLJKmgKZOeHPpk2bSrWzUCVJkiRJ6iQWqyRJkiRJklQbFqskSZIkSZJUGxarJEmSJEmSVBsWqyRJkiQBMDg4yMKFCznttNNYuHAhg4ODrQ5JktSBXA1QklpsTnc/x6/tr67DtdV0M6cb4MxqOtO0q+N95T0l1dvg4CDLly9nzZo17N69m66uLvr6+gDo7e1tcXSSpE5isUqSWuyR4ZXcsbKaf8APDQ3R09NTSV/z+9dX0o9ao473lfeUVG8DAwOsWbOGU0899ek/92vWrGHZsmUWqyRJ08rHACVJkiQxPDzM4sWLn7Ft8eLFDA8PtygiSVKnslglSZIkie7ubjZv3vyMbZs3b6a7u7tFEUmSOpXFKkmSJEksX76cvr4+Nm3axK5du9i0aRN9fX0sX7681aFJkjqMc1ZJkiRJenpeqmXLljE8PEx3dzcDAwPOVyVJmnYWqyRJkiQBjYJVb29vpQt2SJK0r3wMUJIkSZIkSbVhsUqSJEmSJEm1YbFKkiRJkiRJtWGxSpIkqQNExJKI+FFEbIuI/r20e1tEZEQsatr20eK4H0XEb0xPxJIkqVM5wbokSVKbi4guYBVwOrADuDki1mXm1jHt5gAfBL7VtG0BcDbwUuBw4CsR8ZLM3D1d8UuSpM7iyCpJkqT2dxKwLTNvy8wngWuBs8Zp9wngEuDxpm1nAddm5rfFgw8AACAASURBVBOZeTuwrehPkiRpSliskiRJan9HANub3u8otj0tIk4EjsrM9ft6rCRJUpV8DFCSJKnDRcR+wGXAuZPsZymwFGDevHkMDQ1NOraq1TGmOhoZGTFXJZmr8sxVOeapPHNV3kzLlcUqSZKk9nc3cFTT+yOLbaPmAAuBoYgA+FVgXUS8ucSxT8vM1cBqgEWLFmVPT09F4Vdk43pqF1NNDQ0NmauSzFV55qoc81SeuSpvpuXKxwAlSZLa383AcRFxbEQcQGPC9HWjOzPz4cw8LDPnZ+Z84JvAmzPzlqLd2RHxvIg4FjgO+J/TfwmSJKlTlBpZFRFLgCuALuDzmblyzP6jgbXAoUWb/szcEBHzgWHgR0XTb2bm+6sJXZLax/z+sVPETMLGavqae9D+lfSj1qnbfeU91TqZuSsizgNuoPFZ7crM3BIRFwO3ZOa6vRy7JSKuB7YCu4APuBKgJEmaShMWq0oudXwhcH1mfrZY3ngDML/Y95PMPKHasCWpfdyx8szK+prfv77S/jRzeV9prMzcQOMzWvO2i/bQtmfM+wFgYMqCkyRJalLmMcAySx0ncEjxei5wT3UhSpIkSZIkqVOUKVaVWa54BfCuiNhB4xu7ZU37jo2I70bEv0TEaycTrCRJkiRJktpbVasB9gJXZealEXEKcHVELATuBY7OzJ9GxCuBf4qIl2bmz5oPngnLHM+0ZR5byVyVY57KM1f7xlyV4321b8yVJEmSpkuZYlWZ5Yr7gCUAmfmNiDgQOCwz7wOeKLZ/OyJ+ArwEuKX54Novc8zMW+axlcxVOeapPHO1D1yWvTTvq33gfSVJkqRpVOYxwL0udVy4CzgNICK6gQOB+yPihcUE7UTEf6Cx1PFtVQUvSZIkSZKk9jLhyKqSSx1/BPhcRHyIxmTr52ZmRsSvAxdHxE7gKeD9mfnglF2NJEmSJEmSZrRSc1ZNtNRxZm4FXjPOcX8P/P0kY5QkSZIkSVKHqGqCdUnSFIuIcu0umbhNZk4yGkmSJEmaGmXmrJIk1UBmTvizadOmUu0kSZIkqa46fmRV2ZEKZfmPQEnSTLEv/w90xJ4kSZKmS8ePrCozAiEzOeaCLzlaQZLUVsr+P9ARe5IkSZpOHV+skiRJkiRJUn1YrJIkSZIkSVJtWKySJEmSJElSbViskiRJkiRJUm1YrJIkSZIkSVJtWKySJEmSJElSbViskiRJkiRJUm3ManUAkiRJklQ3EVFpf5lZaX+SNKrKv6/q8neVI6skSZIkaYzMLPVzzAVfKtVOkqZKO/5d5cgqSZIkSZKmgSP2pHIcWSVJkqQZLyIm/Lnzkt8s1U6SpkqVI2AsVKmdWaySJEnSjFfmH3WbNm3yH3+SJM0AFqskSZI6QEQsiYgfRcS2iOgfZ//7I+IHEfG9iNgcEQuK7ftHxNpi33BEfHT6o5ckSZ3EYpUkSVKbi4guYBXwRmAB0DtajGryhcw8PjNPAD4FXFZs/13geZl5PPBK4H0RMX9aApckSR3JYpUkSVL7OwnYlpm3ZeaTwLXAWc0NMvNnTW9nA6PPwyUwOyJmAQcBTwLNbSVJkirlaoCSJEnt7whge9P7HcDJYxtFxAeADwMHAK8vNn+RRmHrXuD5wIcy88EpjVaSJHU0i1WSJEkCIDNXAasi4hzgQuC9NEZl7QYOB14A/GtEfCUzbxt7fEQsBZYCzJs3j6GhoekKvZSRkZHaxVRX5mrfmKtyvK/KM0/leE/tm5mUK4tVqszg4CADAwMMDw/T3d3N8uXL6e3tbXVYkiQJ7gaOanp/ZLFtT64FPlu8PgfYmJk7gfsi4uvAIuBZxarMXA2sBli0aFH29PRMPvIKDQ0NUbeY6spc7YON681VSd5XJXlPleY9tQ9m2H1lsUqVGBwcZPny5axZs4bdu3fT1dVFX18fgAUrSZJa72bguIg4lkaR6mwaRainRcRxmfnj4u2ZwOjru2g8Enh1RMwGXg385bRELU2Rl3/8Rh5+bGdl/c3vXz/pPuYetD+3fuyMCqKRpJnPYpUqMTAwwJo1azj11FOfrm6vWbOGZcuWWaySJKnFMnNXRJwH3AB0AVdm5paIuBi4JTPXAedFxBuAncBDNB4BhMYqgn8bEVuAAP42M78//VchVefhx3Zyx8ozK+mrqpEdVRS8JKldWKxSJYaHh1m8ePEzti1evJjh4eEWRSRJkppl5gZgw5htFzW9/uAejhsBfndqo5MkSfoFi1WqRHd3N5s3b+bUU099etvmzZvp7u5uYVSSJEmSJM1MdXxkGabnsWWLVarE8uXL6evre3rOqk2bNtHX18fAwECrQ5MkSZKkKVdlYWEmFRU0der4yDJMz2PLFqtUidF5qZYtW/b0aoADAwPOVyVJkiSpI1RVWJhpRQVpKlisUmV6e3vp7e11+VBJkiRJkvSc7dfqACRJkiRJkqRRpUZWRcQS4AoaSx1/PjNXjtl/NLAWOLRo01+sONO8fyuwIjP/oqLYJ1THych8ZliSJEmSJGnPJixWRUQXsAo4HdgB3BwR6zJza1OzC4HrM/OzEbGAxrLI85v2XwZ8ubKoS6rjZGQ+MyxJkiRJkrRnZR4DPAnYlpm3ZeaTwLXAWWPaJHBI8XoucM/ojoh4C3A7sGXy4UqSJEmSJKmdlSlWHQFsb3q/o9jWbAXwrojYQWNU1TKAiDgYuAD4+KQjlSRJkiRJUturajXAXuCqzLw0Ik4Bro6IhTSKWJdn5khE7PHgiFgKLAWYN28eQ0NDFYVFZX2NjIxU1leV11dHVeaqnZmn8sxVeeaqPHNVnrmSJEnSdCpTrLobOKrp/ZHFtmZ9wBKAzPxGRBwIHAacDPxORHyKxuTrT0XE45n5meaDM3M1sBpg0aJFWcXcUABsXF/JPFNQ3ZxVVcZUV5Xlqs2Zp/LMVXnmqjxzVZ65kiRJ0nQqU6y6GTguIo6lUaQ6GzhnTJu7gNOAqyKiGzgQuD8zXzvaICJWACNjC1WSJEmSJEl6pjnd/Ry/tr+6DtdW082cboBqFrPbkwmLVZm5KyLOA24AuoArM3NLRFwM3JKZ64CPAJ+LiA/RmGz93MzMqQxckiRJkiSpXT0yvJI7VlZTFKpypPz8/vWV9LM3peasyswNNCZOb952UdPrrcBrJuhjxXOIT5IkSZKk2qt0FMwMGgEjTYWqJliXJEmSJKljVTUKZqaNgJGmwn6tDkCSJEmSJEkaZbFKkiRJkiRJtWGxSpIkSZIkSbXhnFWSJEmSOkodl4N3ImxJ+gWLVZIkSZI6Sh2Xg3cibEn6BR8DlCRJkiRJUm1YrJIkSZIkSVJtWKySJEmSJElSbThnlSRJkiRJFahs7rGN1fQz96D9K+lHrVPpfHYz6L6yWCVJktQBImIJcAXQBXw+M1eO2f9+4APAbmAEWJqZW4t9LwP+BjgEeAp4VWY+Po3hS1LtVTVp//z+9ZX1pZmtyvtgpt1XPgYoSZLU5iKiC1gFvBFYAPRGxIIxzb6Qmcdn5gnAp4DLimNnAdcA78/MlwI9wM7pil2SJHUei1WSJEnt7yRgW2belplPAtcCZzU3yMyfNb2dDWTx+gzg+5l5a9Hup5m5expiliRJHcrHACVJktrfEcD2pvc7gJPHNoqIDwAfBg4AXl9sfgmQEXED8ELg2sz81HgniYilwFKAefPmMTQ0VFX8lRgZGaldTHXVCbmq6vqqzFW757wT7quqmKdyvKf2zUzKlcUqSZIkAZCZq4BVEXEOcCHwXhqfFxcDrwJ+DtwUEd/OzJvGOX41sBpg0aJF2dPTM12hlzI0NETdYqqrts/VxvWVXV9luaowpukWEZX2l5kTN2pnM/hemG5t/3dVlWbYfeVjgJIkSe3vbuCopvdHFtv25FrgLcXrHcDXMvOBzPw5sAE4cUqilDQjZWapn2Mu+FKpdpJksUqSJKn93QwcFxHHRsQBwNnAuuYGEXFc09szgR8Xr28Ajo+I5xeTrb8O2DoNMUuSpA7lY4CSJEltLjN3RcR5NApPXcCVmbklIi4GbsnMdcB5EfEGGiv9PUTjEUAy86GIuIxGwSuBDZm5viUXIlVofn+Ft/HGyfc196D9KwhEktqDxSpJkqQOkJkbaDzC17ztoqbXH9zLsdcA10xddNL0umPlmZX1Nb9/faX9SZLavFg1p7uf49f2V9fh2sl3MacbGiPrJUmSJEmSNFZbF6seGV5Z2bccVa0yUOlwY0mSJEmSpDbT1sUqSZIkSZI080REZX25yuTM42qAkiRJkiSpVjJzwp9jLvhSqXaaeRxZJUmSJEnSNCg7WiguKdefhRhBtfdVXe4pR1ZJkiRJkjQNyowC2rRpU6l2dSkqqPWqvK/qwmKVJEmSJEmSasNilSRJkiRJkmrDYpUkSZIkSZJqw2KVJEmSJEmSasNilSRJkiRJkmqjVLEqIpZExI8iYltE9I+z/+iI2BQR342I70fEm4rtJ0XE94qfWyPirVVfgCRJkiRJktrHrIkaREQXsAo4HdgB3BwR6zJza1OzC4HrM/OzEbEA2ADMB34ILMrMXRHxIuDWiPjnzNxV9YVIkiRJkiRp5puwWAWcBGzLzNsAIuJa4CyguViVwCHF67nAPQCZ+fOmNgcW7abV/P711XW2cfJ9zT1o/woCaY2IqLS/zGm/HSRJkiTtg5d//EYefmxnZf1V8e+zuQftz60fO6OCaCTVVZli1RHA9qb3O4CTx7RZAdwYEcuA2cAbRndExMnAlcAxwLunc1TVHSvPrKyv+f3rK+1vJipbXDJXkiRJUnt4+LGdlX22HxoaoqenZ9L9VDogQVItlSlWldELXJWZl0bEKcDVEbEwM5/KzG8BL42IbmBtRHw5Mx9vPjgilgJLAebNm8fQ0FBFYVWrrnHVkbma2MjIiHkqyVyVZ67KM1flmStJnWhfniqISyZu41MFklRemWLV3cBRTe+PLLY16wOWAGTmNyLiQOAw4L7RBpk5HBEjwELgluaDM3M1sBpg0aJFWUW1vXIb11fyLUBHMFelVPXNUicwV+WZq/LMVXnmSlInKltc8u9ISapemdUAbwaOi4hjI+IA4Gxg3Zg2dwGnARQjqA4E7i+OmVVsPwb4j8AdFcUuSZIkSZKkNjPhyKpiJb/zgBuALuDKzNwSERcDt2TmOuAjwOci4kM0JlE/NzMzIhYD/RGxE3gK+KPMfGDKrkaSJEmSJEkzWqk5qzJzA7BhzLaLml5vBV4zznFXA1dPMkZJkiRJUgvM6e7n+LX91XW4dvJdzOkGcEEnqZ1VNcG6JEmSJKnNPDK80tUAJU27ji9WucqHJEmSJEnT4+Ufv5GHH9tZWX9VFS/nHrQ/t37sjEr60uR1fLHKVT4kSZIkSZoeDz+2s3aj9cARe3VTZjVASZIkzXARsSQifhQR2yLiWRPQRMT7I+IHEfG9iNgcEQvG7D86IkYi4k+mL2pJktSJLFZJkiS1uYjoAlYBbwQWAL1ji1HAFzLz+Mw8AfgUcNmY/ZcBX57yYCVJUsfr+McAJUmSOsBJwLbMvA0gIq4FzgK2jjbIzJ81tZ8NPD1XQkS8BbgdeHRaopUkta06rjAJrjJZNxarJEmS2t8RwPam9zuAk8c2iogPAB8GDgBeX2w7GLgAOB3wEUBJ0qTUcYVJcM6qurFYJUmSJAAycxWwKiLOAS4E3gusAC7PzJGJVlGOiKXAUoB58+YxNDQ0pfHuq5GRkdrFVFfmqrxOyFVV11dlrto5595T5VWdq3bO+0y7ryxWCajn8qEuHSpJUmXuBo5qen9ksW1PrgU+W7w+GfidiPgUcCjwVEQ8npmfGXtQZq4GVgMsWrQo67aSsqs7l2euymv7XG1cX9n1VZarCmOqI++p8irNlfdVrVisElDP5UMdhilJUmVuBo6LiGNpFKnOBs5pbhARx2Xmj4u3ZwI/BsjM1za1WQGMjFeokiRJqorFKkmSpDaXmbsi4jzgBqALuDIzt0TExcAtmbkOOC8i3gDsBB6i8QigJEnStLNYJUmS1AEycwOwYcy2i5pef7BEHyuqj0ySJOmZLFZJkiRJkvao0uk5NlYzt62k9maxSpIkSZI0rqrmtYVG0avK/iS1r/1aHYAkSZIkSZI0ypFVAmBOdz/Hr+2vrsO1k+9iTjc0FiOSJEmSVFcRUb7tJRO3ycxJRCOpHVisEgCPDK+sbEju0NAQPT09k+6n0mfjJUmSJE2JssWlqv6dIKn9+RigJEmSJEmSasNilSRJkiRJkmrDxwAlSZIkSdK0qXTKl43V9DX3oP0r6UfVsFglSZIkSZKmRVVzJUOj6FVlf6oPHwOUJEmSJElSbViskiRJkiRJUm1YrJIkSZIkSVJtOGeVnla3Se6c4E6SJEmSpM5jsUqAk9xJkiRJkqR68DFASZIkSZIk1YbFKkmSJEmSJNWGxSpJkiRJkiTVhsUqSZIkSZIk1UapYlVELImIH0XEtojoH2f/0RGxKSK+GxHfj4g3FdtPj4hvR8QPiv++vuoLkCRJkiRJUvuYcDXAiOgCVgGnAzuAmyNiXWZubWp2IXB9Zn42IhYAG4D5wAPAb2XmPRGxELgBOKLia5AkSZIkSVKbKDOy6iRgW2belplPAtcCZ41pk8Ahxeu5wD0AmfndzLyn2L4FOCginjf5sCVJkiRJktSOJhxZRWMk1Pam9zuAk8e0WQHcGBHLgNnAG8bp523AdzLziecQpyRJkiRJkjpAmWJVGb3AVZl5aUScAlwdEQsz8ymAiHgpcAlwxngHR8RSYCnAvHnzGBoaqiis6oyMjNQyrroyVxPznirPXJVnrsozV+WZK0mSJE2nMsWqu4Gjmt4fWWxr1gcsAcjMb0TEgcBhwH0RcSTwj8B7MvMn450gM1cDqwEWLVqUPT09+3IN02JoaIg6xlVLG9ebqxK8p8ozV+WZq/LMVXnmqj1ExBLgCqAL+Hxmrhyz//3AB4DdwAiwNDO3RsTpwErgAOBJ4PzM/Oq0Bi9JkjpKmTmrbgaOi4hjI+IA4Gxg3Zg2dwGnAUREN3AgcH9EHAqsB/oz8+vVhS1JkqSymhbMeSOwAOgtFsVp9oXMPD4zTwA+BVxWbB9dMOd44L3A1dMUtiRJ6lATFqsycxdwHo2V/IZprPq3JSIujog3F80+AvxhRNwKDALnZmYWx70YuCgivlf8/MqUXIkkSZL2ZMIFczLzZ01vZ9NYQMcFcyRJ0rQrNWdVZm4ANozZdlHT663Aa8Y57pPAJycZoyRJkianzII5RMQHgA/TeOTv9eP044I5kiRpylU1wbokSZJmuMxcBayKiHOAC2k89gdMvGBO0abWi+a4WEB55qo8c1WeuSrHPO0bc1XOTLuvLFZJkiS1vzIL5jS7Fvjs6JsyC+ZA/RfNcbGA8sxVeeaqPHNVjnnaBy7uVdpMu6/KTLAuSZKkmW3CBXMi4rimt2cCPy62u2COpEkZHBxk4cKFnHbaaSxc+H/au/tgO+66juPvDwGlFkTaAhaFlgeBK1gCfRAhQgKlgDIw0NYaCrUzAcHRDMrUEQjyIBMFsTJgnaHQlIJTM7SVYqeILaSBGmqfKCEPTWlH2iIiFhSQgkCbfP1jf7c5udybnCT33rPn3vdrZifn7Nnd+9vvOdn9nN/unn0K69evH3WTJPWcZ1ZJkiQtcFV1b5LJG+YsAc6fvGEOcGNVXQb8QZITgXuAb7P7EsDBG+ZM/mbpSVV11/yuhaRxtH79etasWcO6devYuXMnS5YsYdWqVQCsXLlyxK2T1Fd2VkmSJC0CQ9ww5/UzzOcNcyQdsLVr17Ju3TpWrFhx32VI69atY/Xq1XZWSZqRlwFKkiRJkubEjh07WLZs2R7jli1bxo4dO0bUIknjwDOrNLQkw0/77n1PU1UH0RpJkiRJfTcxMcGmTZtYsWLFfeM2bdrExMTECFulcTDs90+/ey5MnlmloVXVUMPGjRuHmk6SJEnSwrZmzRpWrVrFxo0buffee9m4cSOrVq1izZo1o26aes7vnoubZ1ZJkiRJkubE5O9SrV69mh07djAxMcHatWv9vSpJe2VnlSRJkiRpzqxcuZKVK1fe9wPrkrQvXgYoSZIkSZKk3rCzSpIkSZIkSb1hZ5UkSZIkSZJ6w84qSZIkSZIk9YadVZIkSZIkSeoNO6skSZIkSZLUG3ZWSZIkSZIkqTfsrJIkSZIkSVJvpKpG3YY9JPkmcOeo2zGNI4BvjboRY8JaDcc6Dc9aDc9aDc9aDa+PtTqqqh426kZoZj3NdH38LPeVtRqetRqetRqOdRqetRpeH2s1Y57rXWdVXyW5saqOG3U7xoG1Go51Gp61Gp61Gp61Gp610kLhZ3l41mp41mp41mo41ml41mp441YrLwOUJEmSJElSb9hZJUmSJEmSpN6ws2p4Hxx1A8aItRqOdRqetRqetRqetRqetdJC4Wd5eNZqeNZqeNZqONZpeNZqeGNVK3+zSpIkSZIkSb3hmVWSJEmSJEnqjUXbWZXk7mnGPTHJZ5NsTrIjyQeTvKA935zk7iRfbo8/mmR5kkry6oFlLG3jzprfNdJClOSCJKdMM355kstH0SZJkvrCPKdxYaaTpP2zaDurZvB+4L1VtbSqJoC/qaor2vOlwI3A6e35GW2ebcBvDSxjJfCl+W22tHDMdphrXzh+Yy+v35HkiPb4mn21KcmvJ9nevuQcsr/tmbLcu9u/j0xyycEsazYleXaSm5LcO917MYL29LVOb0hyc5ItSTYkOWrUbZoLSe4/6jZI+8k8J/XAYsl0Pc4pvcpz0OtaLfhMN455zs6qPR0JfG3ySVVtHWKeO4EHJnlEkgAvBD41R+3rhSRntP/IX0ryd22j//4k1yT5ysAOYHk7snlJkluSXNhqNDaSvDLJ9W0ndm6SJe2I7Nq2/tcmeUSb9tQk29r4q9u4JUnek+SGVrPXtvHLk3wuyT+2mr0ryentb21N8riBZpyY5MYktyZ58TRtPDTJ+W3eLyZ56bwUZ3wsBWYMNoOq6plDTHY68BftS87/HVTLdv/dr1fVQYeIJEtmoz3AV4Ezgb+fpeXNih7W6YvAcVV1DHAJ8JeztNxZl+TodGeYfKgF8yuTHJLk+LZt2ty2Vdva9GcmuSzJVcCGJA9q4e2mto166cByb2n7gVvbdv7EJJ9PcluSE0a64lqszHNDWEx5Dsx0C0SvM10Pc0ov8xz0slZjkekWW56zs2pP7wWuSvKpJH+U5OeGnO8S4FTgmcBNwI/mqoGjluTJwFuA51bVU4HXt5eOBJYBLwbeNTDL04A/BH4ZeCzwrPlr7cFJMgGcBjyrHYndSbdTOxS4tq3/1cBr2ixvBV7Qxr+kjVsFfLeqjgeOB16T5DHttacCrwMmgFcBT6iqE4DzgNUDTTkaOAH4TeADSR44palrgKvavCuA9yQ59CDWe8GEuSQ/BfwZcFpbn9OSHN427NuTnAdkYPrJoz1Jck66y0Q+Azy8jX813ZH3dya58EBrPE07j56yU/l4kn9uO4e97izbe3N2ki8Bvzbd+9emW9XqeX3bwZ0z0zKr6o6q2gLsmq11nA09rNPGqvpBe3ot8IuztKpz5ZeAv62qJwPfAU4GPgy8dmAbN+jpwClV9Rzgh8DLqurpdNuZs5P7vqw+HjgbeFIbXkG3PzgLePPcrpI0LfPcPiymPAdmOjPd/GS6HuaUXuY56GWtxinTLZo8Z2fVgKr6MN1O5mJgOXBtkp8eYtaL6MLNSmD9nDWwH54LXFxV3wKoqv9p4z9RVbuq6mbgEQPTX19VX6uqXcBmup30uHgecCxwQ5LN7fljgR8Dk6cuf4Hd6/R54IIkrwEme/lPAs5o818HHE63gQG4oar+s6p+BPwbcGUbv5U963RRq+1twFfoNh6DTgLe2P7GZ4EHAo8+kBVeaGGuqn7c2vixdtTsY8DbgE1tA38p09fqZcAT6UL5GXRfXKiq84DLgD+uqtOnr+KsWEr3PvwKXSh71F6mPRS4rr0H/80071+SRwJ/CjyD7gvG1M/QuOpTnVbR/7Mwbq+qze3x5LbrwVX1r23c1COvnx7Yxgf48yRbgM8Av8Dubf3tVbW1bee3Axuqu9Xw1G2ZNC/Mc0NZTHkOzHRmutFkuj7llL7rU636nukWTZ4bu+sW51pVfR04Hzi/9fY+he5DsLd5vpHkHuD5dEemhjntdKEZPPqYGcbvZLw+cwE+UlVv2mNkclb7jwsD61RVr0vyq3Q74y8kObYtY3VVXTFlGcvZsza7Bp7vYs86FXua+jzAyVX15f1Yt5kMhjmAQ4C7+Mkw9/z2eDLMXQR8vI07CTgmu6+NfwhdmPsxLcwBJJka5lYMtOOitqG8LclMYe4l2f3Dt5NhbscQ6/hs4OUAVfXJJN+eYZr1VbUT+Hq6U2fn04aq+i5AkpuBo4B/n2HancA/tMczvX8nAJ+b3FEluRh4wpy1fv70ok5JXgkcBzzngNdkfkzdHh+5j+m/P/D4dOBhwLFVdU+SO+j+301d7t62ZdK8Mc8dsIWY58BMB2a6UWS6XuSUMdGLWo1Jpls0ec4zqwYkeWGSB7THP093xOQ/hpz9rcCftA3hQnYVcGqSwwGSHDbi9sylDcApSSZPFz4se/mxvSSPq6rrquqtwDeBRwFXAL838Ll6wnRHi/bh1CT3S3dK9WOBqQHmCmD15CmcSZ62n8vfYzXowtzSNjyxqt4O3DNTmKO7jOBRdGHucHaHucllPKaqJgPMbIe5yb/x6KoaJtSMi/35UvDDge3OTO/fQjXyOiU5ke6o8EvaEfVx8h3ge+0LGcBv72XahwB3tWCzgi5ESr1knhvKYspzYKYz043GyHPKGBl5rcY40y3YPLeYO6t+JsnXBoY30PXsb0t3/esVdKeFfmOYhVXVNVX1iblscB9U1XZgLfC5Vqe/HnGT5kx1p8C/BbiynSr5afbec/2edNfpbwOutHLmDAAABDBJREFUobuL0HnAzcBNbfy57H/P9FeB6+lOR31dVf1wyuvvBB4AbEmyvT0/UAsxzH0PePDA86vprsEmyYuAh04zz9V0pyAvSXIkex4h7LOZ3r8bgOckeWi6O4GcPMpG9sCs1Kl97s6lCzV3zXWj58gq4EPpLjk5FPjuDNNdCByXZCvdZRS3zFP7pH0xzx2AxZTnwEwHZroxy3TmueGZ6ToLM89VlYODg8N9A91135uBLXSnhz8DuHvg9VOAC9rjj9Od7r0NeB/d0Y37AX8+MH4jXS/+cuDygeV8lu6uGwy+BlwAfIDu1uK3Ai+eZppD6HYoW+muqb58L+tzGN0Oa3Nbt8PpTlXfDnyI7g5QR7Rp727/BjiHLlB9Gvgnuh8mnGzfKbNU68m/dzSwrT0+EzhnYJrLgeX7Wsbe3r82/neB2+h+Z+MjwNq9LPN4ujtpfZ/utwC2j/gz2dc6fQb4r7aczcBlo6zTAdb2QQOP3wi8b9RtcnBwcHCYnWG6fR1mulnPdD3OKb3Kcz2v1VhnOhZonktbIUnSApbkQVV1dzu6dClwflVdOup29c1iq1OS04A30Z0dcCdwZlV9c7StkiRJ01lsOeVgLKZaLdQ8Z2eVJC0CSf4KOJHuRxSvBF5f7gB+gnWSJEl9ZU4ZnrUaf3ZWSVoQkrwAePeU0bdX1ctG0Z7ZluQ6YOqt119VVVsPYplr6G7TPujiqlp7oMscNeskSdJ4W8iZzpwyPGslO6skSZIkSZLUG4v5boCSJEmSJEnqGTurJEmSJEmS1Bt2VkkaS0nuSHLEwU4jSZKk0TDPSZqJnVWSJEmSJEnqDTurJM2bJEcnuSXJBUluTXJhkhOTfD7JbUlOSHJYkk8k2ZLk2iTHtHkPT3Jlku1JzgMysNxXJrk+yeYk5yZZMrKVlCRJWsDMc5Lmg51Vkubb44GzgSe14RXAMuAs4M3AO4AvVtUx7flH23xvAzZV1ZOBS4FHAySZAE4DnlVVS4GdwOnztjaSJEmLj3lO0py6/6gbIGnRub2qtgIk2Q5sqKpKshU4GjgKOBmgqq5qR+B+Fng28PI2/pNJvt2W9zzgWOCGJACHAHfN4/pIkiQtNuY5SXPKzipJ8+1HA493DTzfRbdNumc/lxfgI1X1pllomyRJkvbNPCdpTnkZoKS++Rfaad9JlgPfqqr/Ba6mO8WcJC8CHtqm3wCckuTh7bXDkhw1342WJEnSfcxzkg6KZ1ZJ6pu3A+cn2QL8APidNv4dwPp2qvk1wFcBqurmJG8BrkxyP7ojeb8P3DnfDZckSRJgnpN0kFJVo26DJEmSJEmSBHgZoCRJkiRJknrEzipJkiRJkiT1hp1VkiRJkiRJ6g07qyRJkiRJktQbdlZJkiRJkiSpN+yskiRJkiRJUm/YWSVJkiRJkqTesLNKkiRJkiRJvfH/OAFtbCu/cOIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAvc56m81yUH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}