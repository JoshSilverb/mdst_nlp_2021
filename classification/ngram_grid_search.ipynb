{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000000\n",
    "Vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode='tf_idf', ngrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer.adapt(np.array(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246970\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(vocab)\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.Sequential([\n",
    "#    Vectorizer,\n",
    "#    tf.keras.layers.Dense(32, activation='relu'),\n",
    "#    tf.keras.layers.Dense(3, activation='softmax')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons=10, layers=2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Vectorizer)\n",
    "    \n",
    "    for n in range(layers):\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "             optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#             optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "#             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels_bools = []\n",
    "\n",
    "for author in y:\n",
    "    if \"EAP\" == author:\n",
    "        training_labels_bools.append([1,0,0])\n",
    "    elif \"HPL\" == author:\n",
    "        training_labels_bools.append([0,1,0])\n",
    "    elif \"MWS\" == author:\n",
    "        training_labels_bools.append([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_labels_bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['But this discovery was so great and overwhelming that all the steps by which I had been progressively led to it were obliterated, and I beheld only the result.',\n",
       "       'I said to myself, \"This is no dream, for by what means can I prove the greater reality of that other life in the house of stone and brick south of the sinister swamp and the cemetery on the low hillock, where the Pole Star peers into my north window each night?\"',\n",
       "       'A robin red breast dropt from the frosty branches of the trees, upon the congealed rivulet; its panting breast and half closed eyes shewed that it was dying: a hawk appeared in the air; sudden fear seized the little creature; it exerted its last strength, throwing itself on its back, raising its talons in impotent defence against its powerful enemy.',\n",
       "       ...,\n",
       "       'The manner in which Wyatt received this harmless pleasantry convinced me, at once, that he was mad.',\n",
       "       'She first assured him of her boundless confidence; of this he must be conscious, since but for that she would not seek to detain him.',\n",
       "       'Thus it is abundantly clear that the gang quitted the BarriÃ¨re du Roule prior to the screams overheard ?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=10 ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 8s 13ms/step - loss: 0.6573 - accuracy: 0.7238\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=10, score=-0.448, total=   9.7s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=10 ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 8s 13ms/step - loss: 0.6568 - accuracy: 0.7205\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=10, score=-0.457, total=  10.0s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=10 ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   19.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 9s 14ms/step - loss: 0.6487 - accuracy: 0.7325\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=10, score=-0.450, total=  10.5s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=15 ...................\n",
      "612/612 [==============================] - 11s 17ms/step - loss: 0.6260 - accuracy: 0.7431\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=15, score=-0.432, total=  12.6s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=15 ...................\n",
      "612/612 [==============================] - 12s 19ms/step - loss: 0.6304 - accuracy: 0.7373\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=15, score=-0.432, total=  13.6s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=15 ...................\n",
      "612/612 [==============================] - 12s 19ms/step - loss: 0.6174 - accuracy: 0.7444\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=15, score=-0.448, total=  14.1s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=20 ...................\n",
      "612/612 [==============================] - 15s 24ms/step - loss: 0.6113 - accuracy: 0.7467\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=20, score=-0.446, total=  17.1s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=20 ...................\n",
      "612/612 [==============================] - 15s 24ms/step - loss: 0.6135 - accuracy: 0.7457\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=20, score=-0.447, total=  17.5s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 26ms/step - loss: 0.6086 - accuracy: 0.7559\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=20, score=-0.431, total=  18.2s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=25 ...................\n",
      "612/612 [==============================] - 17s 28ms/step - loss: 0.5914 - accuracy: 0.7568\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=25, score=-0.427, total=  20.4s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 29ms/step - loss: 0.6041 - accuracy: 0.7505\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=25, score=-0.452, total=  20.8s\n",
      "[CV] batch_size=16, epochs=1, layers=1, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 28ms/step - loss: 0.5961 - accuracy: 0.7615\n",
      "[CV]  batch_size=16, epochs=1, layers=1, neurons=25, score=-0.440, total=  20.4s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=10 ...................\n",
      "612/612 [==============================] - 12s 18ms/step - loss: 0.7673 - accuracy: 0.6577\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=10, score=-0.480, total=  13.7s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 18ms/step - loss: 0.7810 - accuracy: 0.6471\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=10, score=-0.501, total=  13.3s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 18ms/step - loss: 0.8133 - accuracy: 0.6276\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=10, score=-0.528, total=  13.3s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=15 ...................\n",
      "612/612 [==============================] - 14s 22ms/step - loss: 0.7090 - accuracy: 0.6978\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=15, score=-0.463, total=  15.9s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=15 ...................\n",
      "612/612 [==============================] - 14s 22ms/step - loss: 0.7235 - accuracy: 0.6894\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=15, score=-0.470, total=  16.5s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=15 ...................\n",
      "612/612 [==============================] - 14s 22ms/step - loss: 0.7147 - accuracy: 0.6889\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=15, score=-0.478, total=  16.0s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=20 ...................\n",
      "612/612 [==============================] - 17s 27ms/step - loss: 0.6771 - accuracy: 0.7162\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=20, score=-0.454, total=  19.1s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=20 ...................\n",
      "612/612 [==============================] - 17s 26ms/step - loss: 0.6778 - accuracy: 0.7162\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=20, score=-0.474, total=  18.9s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 26ms/step - loss: 0.6625 - accuracy: 0.7294\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=20, score=-0.446, total=  18.6s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 29ms/step - loss: 0.6676 - accuracy: 0.7242\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=25, score=-0.456, total=  20.5s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 28ms/step - loss: 0.6595 - accuracy: 0.7143\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=25, score=-0.455, total=  20.0s\n",
      "[CV] batch_size=16, epochs=1, layers=2, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 29ms/step - loss: 0.6521 - accuracy: 0.7286\n",
      "[CV]  batch_size=16, epochs=1, layers=2, neurons=25, score=-0.436, total=  20.4s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 17ms/step - loss: 0.9614 - accuracy: 0.5175\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=10, score=-0.766, total=  13.3s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 17ms/step - loss: 0.9718 - accuracy: 0.5189\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=10, score=-0.717, total=  13.0s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 17ms/step - loss: 0.8654 - accuracy: 0.6098\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=10, score=-0.634, total=  12.9s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=15 ...................\n",
      "612/612 [==============================] - 13s 21ms/step - loss: 0.8642 - accuracy: 0.5941\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=15, score=-0.528, total=  15.1s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=15 ...................\n",
      "612/612 [==============================] - 13s 20ms/step - loss: 0.8414 - accuracy: 0.6155\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=15, score=-0.512, total=  14.8s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=15 ...................\n",
      "612/612 [==============================] - 13s 20ms/step - loss: 0.8447 - accuracy: 0.6065\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=15, score=-0.523, total=  15.3s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 25ms/step - loss: 0.8260 - accuracy: 0.6155\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=20, score=-0.514, total=  18.4s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 26ms/step - loss: 0.8524 - accuracy: 0.5955\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=20, score=-0.542, total=  18.3s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 25ms/step - loss: 0.8401 - accuracy: 0.6100\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=20, score=-0.569, total=  18.0s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 28ms/step - loss: 0.8051 - accuracy: 0.6343\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=25, score=-0.509, total=  19.8s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 28ms/step - loss: 0.7776 - accuracy: 0.6572\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=25, score=-0.495, total=  19.9s\n",
      "[CV] batch_size=16, epochs=1, layers=4, neurons=25 ...................\n",
      "612/612 [==============================] - 17s 28ms/step - loss: 0.7744 - accuracy: 0.6581\n",
      "[CV]  batch_size=16, epochs=1, layers=4, neurons=25, score=-0.482, total=  19.7s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=10 ...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 11s 17ms/step - loss: 0.9979 - accuracy: 0.4941\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=10, score=-0.852, total=  12.8s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 17ms/step - loss: 1.0030 - accuracy: 0.4891\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=10, score=-0.872, total=  13.0s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=10 ...................\n",
      "612/612 [==============================] - 11s 16ms/step - loss: 0.9931 - accuracy: 0.5038\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=10, score=-0.838, total=  12.7s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=15 ...................\n",
      "612/612 [==============================] - 14s 21ms/step - loss: 0.9138 - accuracy: 0.5942\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=15, score=-0.609, total=  15.6s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=15 ...................\n",
      "612/612 [==============================] - 14s 21ms/step - loss: 0.9598 - accuracy: 0.5198\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=15, score=-0.827, total=  15.5s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=15 ...................\n",
      "612/612 [==============================] - 13s 21ms/step - loss: 0.9376 - accuracy: 0.5752\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=15, score=-0.625, total=  15.5s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 24ms/step - loss: 0.8886 - accuracy: 0.5586\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=20, score=-0.646, total=  17.8s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 26ms/step - loss: 0.9096 - accuracy: 0.5882\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=20, score=-0.687, total=  18.5s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=20 ...................\n",
      "612/612 [==============================] - 16s 25ms/step - loss: 0.8818 - accuracy: 0.5999\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=20, score=-0.542, total=  18.4s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=25 ...................\n",
      "612/612 [==============================] - 19s 29ms/step - loss: 0.8923 - accuracy: 0.5809\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=25, score=-0.630, total=  21.1s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=25 ...................\n",
      "612/612 [==============================] - 18s 28ms/step - loss: 0.8732 - accuracy: 0.5888\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=25, score=-0.541, total=  20.7s\n",
      "[CV] batch_size=16, epochs=1, layers=6, neurons=25 ...................\n",
      "612/612 [==============================] - 17s 26ms/step - loss: 0.8771 - accuracy: 0.5854\n",
      "[CV]  batch_size=16, epochs=1, layers=6, neurons=25, score=-0.599, total=  19.1s\n",
      "[CV] batch_size=32, epochs=1, layers=1, neurons=10 ...................\n",
      "306/306 [==============================] - 7s 23ms/step - loss: 0.7171 - accuracy: 0.6858\n",
      "[CV]  batch_size=32, epochs=1, layers=1, neurons=10, score=-0.484, total=   9.2s\n",
      "[CV] batch_size=32, epochs=1, layers=1, neurons=10 ...................\n",
      "306/306 [==============================] - 7s 23ms/step - loss: 0.6909 - accuracy: 0.7081\n",
      "[CV]  batch_size=32, epochs=1, layers=1, neurons=10, score=-0.462, total=   9.3s\n",
      "[CV] batch_size=32, epochs=1, layers=1, neurons=10 ...................\n",
      " 90/306 [=======>......................] - ETA: 5s - loss: 0.9117 - accuracy: 0.5785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-010aca99383d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, batch_size=32, verbose=1)\n",
    "\n",
    "batches = [16, 32, 64]\n",
    "neurons = [10, 15, 20, 25]\n",
    "layers = [1, 2, 4, 6]\n",
    "epochs = [1]\n",
    "\n",
    "param_grid = dict(neurons=neurons, epochs=epochs, layers=layers, batch_size=batches)\n",
    "grid = GridSearchCV(estimator=model, scoring='neg_log_loss', param_grid=param_grid, n_jobs=1, cv=3, verbose=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.451206 (0.010626) with: {'epochs': 1, 'layers': 1, 'neurons': 10}\n",
      "-0.444123 (0.001995) with: {'epochs': 1, 'layers': 1, 'neurons': 15}\n",
      "-0.439087 (0.008581) with: {'epochs': 1, 'layers': 1, 'neurons': 20}\n",
      "-0.429369 (0.005241) with: {'epochs': 1, 'layers': 1, 'neurons': 25}\n",
      "-0.519594 (0.043255) with: {'epochs': 1, 'layers': 2, 'neurons': 10}\n",
      "-0.469815 (0.001766) with: {'epochs': 1, 'layers': 2, 'neurons': 15}\n",
      "-0.458230 (0.007228) with: {'epochs': 1, 'layers': 2, 'neurons': 20}\n",
      "-0.449325 (0.004645) with: {'epochs': 1, 'layers': 2, 'neurons': 25}\n",
      "-0.728966 (0.068606) with: {'epochs': 1, 'layers': 4, 'neurons': 10}\n",
      "-0.637830 (0.018364) with: {'epochs': 1, 'layers': 4, 'neurons': 15}\n",
      "-0.506345 (0.006745) with: {'epochs': 1, 'layers': 4, 'neurons': 20}\n",
      "-0.499139 (0.009262) with: {'epochs': 1, 'layers': 4, 'neurons': 25}\n",
      "-0.870501 (0.044818) with: {'epochs': 1, 'layers': 6, 'neurons': 10}\n",
      "-0.807303 (0.037110) with: {'epochs': 1, 'layers': 6, 'neurons': 15}\n",
      "-0.732095 (0.090398) with: {'epochs': 1, 'layers': 6, 'neurons': 20}\n",
      "-0.675731 (0.075056) with: {'epochs': 1, 'layers': 6, 'neurons': 25}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('%f (%f) with: %r' % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.429369</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>{'epochs': 1, 'layers': 1, 'neurons': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.439087</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>{'epochs': 1, 'layers': 1, 'neurons': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444123</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>{'epochs': 1, 'layers': 1, 'neurons': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.449325</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>{'epochs': 1, 'layers': 2, 'neurons': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.451206</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>{'epochs': 1, 'layers': 1, 'neurons': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.458230</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>{'epochs': 1, 'layers': 2, 'neurons': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.469815</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>{'epochs': 1, 'layers': 2, 'neurons': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.499139</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>{'epochs': 1, 'layers': 4, 'neurons': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.506345</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>{'epochs': 1, 'layers': 4, 'neurons': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.519594</td>\n",
       "      <td>0.043255</td>\n",
       "      <td>{'epochs': 1, 'layers': 2, 'neurons': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.637830</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>{'epochs': 1, 'layers': 4, 'neurons': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.675731</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>{'epochs': 1, 'layers': 6, 'neurons': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.728966</td>\n",
       "      <td>0.068606</td>\n",
       "      <td>{'epochs': 1, 'layers': 4, 'neurons': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.732095</td>\n",
       "      <td>0.090398</td>\n",
       "      <td>{'epochs': 1, 'layers': 6, 'neurons': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.807303</td>\n",
       "      <td>0.037110</td>\n",
       "      <td>{'epochs': 1, 'layers': 6, 'neurons': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.870501</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>{'epochs': 1, 'layers': 6, 'neurons': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean     stdev                                     params\n",
       "3  -0.429369  0.005241  {'epochs': 1, 'layers': 1, 'neurons': 25}\n",
       "2  -0.439087  0.008581  {'epochs': 1, 'layers': 1, 'neurons': 20}\n",
       "1  -0.444123  0.001995  {'epochs': 1, 'layers': 1, 'neurons': 15}\n",
       "7  -0.449325  0.004645  {'epochs': 1, 'layers': 2, 'neurons': 25}\n",
       "0  -0.451206  0.010626  {'epochs': 1, 'layers': 1, 'neurons': 10}\n",
       "6  -0.458230  0.007228  {'epochs': 1, 'layers': 2, 'neurons': 20}\n",
       "5  -0.469815  0.001766  {'epochs': 1, 'layers': 2, 'neurons': 15}\n",
       "11 -0.499139  0.009262  {'epochs': 1, 'layers': 4, 'neurons': 25}\n",
       "10 -0.506345  0.006745  {'epochs': 1, 'layers': 4, 'neurons': 20}\n",
       "4  -0.519594  0.043255  {'epochs': 1, 'layers': 2, 'neurons': 10}\n",
       "9  -0.637830  0.018364  {'epochs': 1, 'layers': 4, 'neurons': 15}\n",
       "15 -0.675731  0.075056  {'epochs': 1, 'layers': 6, 'neurons': 25}\n",
       "8  -0.728966  0.068606  {'epochs': 1, 'layers': 4, 'neurons': 10}\n",
       "14 -0.732095  0.090398  {'epochs': 1, 'layers': 6, 'neurons': 20}\n",
       "13 -0.807303  0.037110  {'epochs': 1, 'layers': 6, 'neurons': 15}\n",
       "12 -0.870501  0.044818  {'epochs': 1, 'layers': 6, 'neurons': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame({\n",
    "    \"mean\": means,\n",
    "    \"stdev\": stds,\n",
    "    \"params\": params\n",
    "})\n",
    "scores.sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 9s 39ms/step - loss: 0.5626 - accuracy: 0.7675 - val_loss: 0.3762 - val_accuracy: 0.8547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb475cd6d00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(neurons=25, layers=1).fit(list(X_train), y_train, epochs=1, batch_size=64,\n",
    "         validation_data=(list(X_test),y_test),\n",
    "         validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-948a22f5d97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "X_sub = test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.6715729e-04, 1.9040395e-05, 9.9941385e-01],\n",
       "       [1.0000000e+00, 2.1028919e-10, 4.9274198e-09],\n",
       "       [2.4573201e-06, 9.9998271e-01, 1.4841148e-05],\n",
       "       ...,\n",
       "       [9.9999821e-01, 6.4516219e-09, 1.8274793e-06],\n",
       "       [8.3473593e-02, 1.1622645e-07, 9.1652632e-01],\n",
       "       [3.9207583e-04, 9.9960798e-01, 4.3928186e-09]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_pred = model.predict(X_sub)\n",
    "sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>1.904040e-05</td>\n",
       "      <td>9.994138e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.102892e-10</td>\n",
       "      <td>4.927420e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.999827e-01</td>\n",
       "      <td>1.484115e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1.609015e-05</td>\n",
       "      <td>3.156577e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.176412</td>\n",
       "      <td>2.596113e-01</td>\n",
       "      <td>5.639762e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP           HPL           MWS\n",
       "0  id02310  0.000567  1.904040e-05  9.994138e-01\n",
       "1  id24541  1.000000  2.102892e-10  4.927420e-09\n",
       "2  id00134  0.000002  9.999827e-01  1.484115e-05\n",
       "3  id27757  0.999981  1.609015e-05  3.156577e-06\n",
       "4  id04081  0.176412  2.596113e-01  5.639762e-01"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"EAP\": sub_pred[:, 0],\n",
    "    \"HPL\": sub_pred[:, 1],\n",
    "    \"MWS\": sub_pred[:, 2]\n",
    "})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
