{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram, cnn, lstm, hybrid, transformer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict,KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/davismalmer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "df['text_no_stopwords'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"].copy()\n",
    "#X = df[\"text\"]\n",
    "\n",
    "authors = df[\"author\"].copy()\n",
    "\n",
    "# Label data\n",
    "y = []\n",
    "for author in authors:\n",
    "    if author == \"EAP\":\n",
    "        y.append([1, 0, 0])\n",
    "    if author == \"HPL\":\n",
    "        y.append([0, 1, 0])\n",
    "    if author == \"MWS\":\n",
    "        y.append([0, 0, 1])\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "y_one_vector = []\n",
    "for author in authors:\n",
    "    if author == \"EAP\":\n",
    "        y_one_vector.append(0)\n",
    "    if author == \"HPL\":\n",
    "        y_one_vector.append(1)\n",
    "    if author == \"MWS\":\n",
    "        y_one_vector.append(2)\n",
    "\n",
    "y_one_vector = np.array(y_one_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.TextVectorization()\n",
    "encoder.adapt(X)\n",
    "\n",
    "max_features = 1000000\n",
    "Vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode='tf_idf', ngrams=2)\n",
    "with tf.device('/device:CPU:0'):\n",
    "    Vectorizer.adapt(X)\n",
    "\n",
    "vocab = encoder.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d(tf.keras.Model):\n",
    "    def __init__(self, conv1_filters, conv1_size, conv2_filters, conv2_size, dense1, encoder):\n",
    "        super(CNN1d, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        vocab = encoder.get_vocabulary()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=len(vocab),output_dim=64,mask_zero=True)\n",
    "        \n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=conv1_filters,\n",
    "                            kernel_size=conv1_size,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            data_format=\"channels_last\",\n",
    "                            )\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=conv2_filters,\n",
    "                            kernel_size=conv2_size,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            data_format=\"channels_last\",\n",
    "                            )\n",
    "        self.global_pool = tf.keras.layers.GlobalMaxPool1D(keepdims=False)\n",
    "        self.dense1 = tf.keras.layers.Dense(dense1, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        emb = self.encoder(x)\n",
    "        emb = self.embedding(emb)\n",
    "        conv1 = self.conv1(emb)\n",
    "        conv2 = self.conv2(emb)\n",
    "        z = tf.concat([conv1, conv2], axis=2)\n",
    "        z = self.global_pool(z)\n",
    "        z = self.dense1(z)\n",
    "        z = self.dense2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(conv1_filters, conv1_size, conv2_filters, conv2_size, dense1):\n",
    "    model = CNN1d(conv1_filters, conv1_size, conv2_filters, conv2_size, dense1, encoder)\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_ngram():\n",
    "    model_ngram = tf.keras.Sequential()\n",
    "    model_ngram.add(Vectorizer)\n",
    "      \n",
    "    model_ngram.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "    model_ngram.add(tf.keras.layers.Dropout(0.2))\n",
    "      \n",
    "    model_ngram.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "      \n",
    "    model_ngram.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                metrics=['accuracy'])\n",
    "    return model_ngram\n",
    "\n",
    "def create_lstm():\n",
    "    LSTM = tf.keras.Sequential()\n",
    "    LSTM.add(encoder)\n",
    "    LSTM.add(tf.keras.layers.Embedding(input_dim=len(vocab),output_dim=64,mask_zero=True))\n",
    "      \n",
    "    LSTM.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,dropout=0.2,return_sequences=True)))\n",
    "    LSTM.add(tf.keras.layers.GlobalMaxPool1D())\n",
    "\n",
    "    LSTM.add(tf.keras.layers.Dropout(0.2))\n",
    "      \n",
    "    LSTM.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "      \n",
    "    LSTM.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return LSTM\n",
    "\n",
    "def create_transformer():\n",
    "    sequence_length = 100\n",
    "    max_features = 1000000\n",
    "    # Token locations\n",
    "    Vectorizer_transformer = tf.keras.layers.TextVectorization(max_tokens=max_features,output_sequence_length=sequence_length) \n",
    "    Vectorizer_transformer.adapt(X)\n",
    "    vocab = Vectorizer_transformer.get_vocabulary()\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "    embed_dim =32  # Embedding size for each token\n",
    "    num_heads =2  # Number of attention heads\n",
    "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "    maxlen = sequence_length\n",
    "    dropout_rate = 0.3 # Dropout rate of feed forward network \n",
    "\n",
    "    ## Build embedding and transformer\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim,dropout_rate)\n",
    "\n",
    "    ## Connect Keras Layers\n",
    "    inputs = tf.keras.Input(shape=(1,), dtype=tf.string) \n",
    "    vec = Vectorizer_transformer(inputs)\n",
    "    x = embedding_layer(vec)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "    transformer = keras.Model(inputs=inputs, outputs=outputs) ##Final Model\n",
    "    \n",
    "    transformer.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "    return transformer\n",
    "\n",
    "def create_hybrid(conv_filters, conv_size, lstm_units, dense_units):\n",
    "    model = tf.keras.Sequential([\n",
    "      encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vocab),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Conv1D(filters=conv_filters,\n",
    "                            kernel_size=conv_size,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            data_format=\"channels_last\",\n",
    "                            ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=False)),\n",
    "    # tf.keras.layers.GlobalMaxPool1D(keepdims=False),\n",
    "    tf.keras.layers.Dense(dense_units, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_ensemble():\n",
    "    ensemble = tf.keras.Sequential()\n",
    "    # for 3 model\n",
    "    ensemble.add(tf.keras.layers.Dense(36, activation='relu'))\n",
    "    ensemble.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    ensemble.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "    #ensemble.add(tf.keras.layers.InputLayer())\n",
    "\n",
    "    ensemble.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = 1000000\n",
    "tfidf_vec = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode='tf_idf', sparse=True, ngrams=2)\n",
    "\n",
    "with tf.device('/device:CPU:0'):\n",
    "  tfidf_vec.adapt(X)\n",
    "\n",
    "tdidf = tf.keras.Sequential([\n",
    "    tfidf_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>average</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, average, logloss]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['model', 'average', 'logloss'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408/408 [==============================] - 9s 21ms/step - loss: 0.7219 - accuracy: 0.6698\n",
      "204/204 [==============================] - 7s 33ms/step - loss: 0.6510 - accuracy: 0.7377\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 19s 65ms/step - loss: 0.8207 - accuracy: 0.6186\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 15s 73ms/step - loss: 0.3065 - accuracy: 0.8924\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 14s 63ms/step - loss: 0.9509 - accuracy: 0.5506\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 13s 66ms/step - loss: 0.3491 - accuracy: 0.8652\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 19s 76ms/step - loss: 0.8223 - accuracy: 0.6059\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 16s 78ms/step - loss: 0.3009 - accuracy: 0.8892\n",
      "Epoch 1/2\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 0.4249 - accuracy: 0.9378\n",
      "Epoch 2/2\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 5s 80ms/step - loss: 0.5219 - accuracy: 0.8624\n",
      "204/204 [==============================] - 3s 13ms/step - loss: 0.4341 - accuracy: 0.8293\n",
      "204/204 [==============================] - 5s 10ms/step - loss: 0.4705 - accuracy: 0.8169\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.4785 - accuracy: 0.8099\n",
      "204/204 [==============================] - 3s 15ms/step - loss: 0.4407 - accuracy: 0.8218\n",
      "204/204 [==============================] - 3s 9ms/step - loss: 0.4773 - accuracy: 0.8096\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8384\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8439\n",
      "408/408 [==============================] - 13s 30ms/step - loss: 0.7192 - accuracy: 0.6742\n",
      "204/204 [==============================] - 10s 47ms/step - loss: 0.6413 - accuracy: 0.7447\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 26s 91ms/step - loss: 0.8319 - accuracy: 0.6025\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 17s 86ms/step - loss: 0.3226 - accuracy: 0.8832\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 16s 70ms/step - loss: 0.9754 - accuracy: 0.5216\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 14s 69ms/step - loss: 0.3725 - accuracy: 0.8551\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 19s 79ms/step - loss: 0.8215 - accuracy: 0.6065\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 17s 82ms/step - loss: 0.2958 - accuracy: 0.8907\n",
      "Epoch 1/2\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.9422\n",
      "Epoch 2/2\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 5s 84ms/step - loss: 0.5488 - accuracy: 0.8468\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 0.4263 - accuracy: 0.8339\n",
      "204/204 [==============================] - 5s 10ms/step - loss: 0.4669 - accuracy: 0.8180\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.8074\n",
      "204/204 [==============================] - 3s 15ms/step - loss: 0.4861 - accuracy: 0.8051\n",
      "204/204 [==============================] - 3s 9ms/step - loss: 0.4818 - accuracy: 0.8123\n",
      "204/204 [==============================] - 0s 816us/step - loss: 0.4405 - accuracy: 0.8432\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8455\n",
      "408/408 [==============================] - 13s 29ms/step - loss: 0.7160 - accuracy: 0.6750\n",
      "204/204 [==============================] - 9s 44ms/step - loss: 0.6311 - accuracy: 0.7463\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 26s 91ms/step - loss: 0.8035 - accuracy: 0.6232\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 18s 90ms/step - loss: 0.2967 - accuracy: 0.8914\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 15s 69ms/step - loss: 1.0073 - accuracy: 0.5032\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 14s 70ms/step - loss: 0.4189 - accuracy: 0.8358\n",
      "Epoch 1/2\n",
      "204/204 [==============================] - 20s 81ms/step - loss: 0.7799 - accuracy: 0.6268\n",
      "Epoch 2/2\n",
      "204/204 [==============================] - 17s 83ms/step - loss: 0.2590 - accuracy: 0.9067\n",
      "Epoch 1/2\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8522 - accuracy: 0.6665\n",
      "Epoch 2/2\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_19/dense_40/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_19/dense_40/embedding_lookup_sparse/Reshape:0\", shape=(None, 36), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_19/dense_40/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 5s 84ms/step - loss: 0.5055 - accuracy: 0.8643\n",
      "204/204 [==============================] - 3s 13ms/step - loss: 0.4193 - accuracy: 0.8367\n",
      "204/204 [==============================] - 5s 11ms/step - loss: 0.4589 - accuracy: 0.8221\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.8016\n",
      "204/204 [==============================] - 4s 17ms/step - loss: 0.4581 - accuracy: 0.8236\n",
      "204/204 [==============================] - 3s 9ms/step - loss: 0.5130 - accuracy: 0.8166\n",
      "204/204 [==============================] - 0s 797us/step - loss: 0.4430 - accuracy: 0.8373\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8435\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    \n",
    "    x_train_sparce = tdidf.predict(X_train)\n",
    "    x_test_sparce = tdidf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cnn = create_model(128, 6, 128, 5, 128)\n",
    "    ngram = create_ngram()\n",
    "    LSTM = create_lstm()\n",
    "    transformer = create_transformer()\n",
    "    hybrid = create_hybrid(64, 5, 64, 64)\n",
    "    ensemble = create_ensemble()\n",
    "    ensemble_with_tdidf = create_ensemble()\n",
    "\n",
    "    cnn.fit(X_train, y_train, epochs=1 )\n",
    "\n",
    "    ngram.fit(X_train, y_train, epochs=1, batch_size=64)\n",
    "\n",
    "    LSTM.fit(X_train, y_train, epochs=2, batch_size=64)\n",
    "    \n",
    "    transformer.fit(X_train, y_train, epochs=2, batch_size=64)\n",
    "    \n",
    "    hybrid.fit(X_train, y_train, epochs=2, batch_size=64)\n",
    "\n",
    "\n",
    "    cnn_pred = cnn.predict(X_train)\n",
    "    ngram_pred = ngram.predict(X_train)\n",
    "    LSTM_pred = LSTM.predict(X_train)\n",
    "    transformer_pred = transformer.predict(X_train)\n",
    "    hybrid_pred = hybrid.predict(X_train)\n",
    "\n",
    "    cnn_pred_test = cnn.predict(X_test)\n",
    "    ngram_pred_test = ngram.predict(X_test)\n",
    "    LSTM_pred_test = LSTM.predict(X_test)\n",
    "    transformer_pred_test = transformer.predict(X_test)\n",
    "    hybrid_pred_test = hybrid.predict(X_test)\n",
    "\n",
    "    X_train_ens = np.hstack([ngram_pred,cnn_pred,LSTM_pred,transformer_pred,hybrid_pred])\n",
    "    X_test_ens = np.hstack([ngram_pred_test,cnn_pred_test,LSTM_pred_test,transformer_pred_test,hybrid_pred_test])\n",
    "\n",
    "    X_train_final_tensor = tf.sparse.from_dense(X_train_ens)\n",
    "    X_test_final_tensor = tf.sparse.from_dense(X_test_ens)\n",
    "    X_train_concat_tensor = tf.sparse.concat(1,[x_train_sparce, X_train_final_tensor])\n",
    "    X_test_concat_tensor = tf.sparse.concat(1,[x_test_sparce, X_test_final_tensor])\n",
    "\n",
    "\n",
    "    ensemble.fit(X_train_ens, y_train, epochs=2, batch_size=128)\n",
    "    ensemble_with_tdidf.fit(X_train_concat_tensor, y_train, epochs=1, batch_size=256)\n",
    "\n",
    "    ngram_results = ngram.evaluate(X_test,y_test)\n",
    "    LSTM_results =LSTM.evaluate(X_test,y_test)\n",
    "    cnn_results =cnn.evaluate(X_test,y_test)\n",
    "    transformer_results = transformer.evaluate(X_test,y_test)\n",
    "    hybrid_results = hybrid.evaluate(X_test,y_test)\n",
    "    ensemble_results =ensemble.evaluate(X_test_ens,y_test)\n",
    "    ensemble_with_tdidf_results =ensemble_with_tdidf.evaluate(X_test_concat_tensor,y_test)\n",
    "\n",
    "\n",
    "\n",
    "    lin_reg = LinearRegression(fit_intercept=False, positive= True)\n",
    "    lin_reg.fit(X_train_ens, y_train)\n",
    "    linreg_logloss = log_loss(y_test,lin_reg.predict(X_test_ens))\n",
    "    linreg_acc = np.sum(np.argmax(y_test, axis = 1) == np.argmax(lin_reg.predict(X_test_ens), axis = 1))/len(np.argmax(y_test, axis = 1))\n",
    "\n",
    "\n",
    "    lin_reg2 = LinearRegression(fit_intercept=False, positive= True)\n",
    "    lin_reg2.fit(np.hstack((X_train_ens,ensemble_with_tdidf.predict(X_train_concat_tensor))), y_train)\n",
    "    linreg2_logloss = log_loss(y_test,lin_reg2.predict(np.hstack((X_test_ens,ensemble_with_tdidf.predict(X_test_concat_tensor)\n",
    "    ))))\n",
    "    linreg2_acc = np.sum(np.argmax(y_test, axis = 1) == np.argmax(lin_reg2.predict(np.hstack((X_test_ens,ensemble_with_tdidf.predict(X_test_concat_tensor)\n",
    "    ))), axis = 1))/len(np.argmax(y_test, axis = 1))\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame({\"model\":['ngram', 'cnn', 'LSTM','transformer','hybrid','ensemble','ensemble_tdidf','lin_reg_1','lin_reg_2'],\\\n",
    "                    \"average\":[ngram_results[1],cnn_results[1],LSTM_results[1],transformer_results[1],hybrid_results[1],ensemble_results[1],ensemble_with_tdidf_results[1],\\\n",
    "                                linreg_acc, linreg2_acc],\\\n",
    "                    \"logloss\":[ngram_results[0],cnn_results[0],LSTM_results[0],transformer_results[0],hybrid_results[0],ensemble_results[0],ensemble_with_tdidf_results[0],\\\n",
    "                                linreg_logloss, linreg2_logloss]})\n",
    "\n",
    "    df = df.append(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">average</th>\n",
       "      <th colspan=\"8\" halign=\"left\">logloss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.818990</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.816914</td>\n",
       "      <td>0.817437</td>\n",
       "      <td>0.817959</td>\n",
       "      <td>0.820028</td>\n",
       "      <td>0.822096</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.458935</td>\n",
       "      <td>0.462924</td>\n",
       "      <td>0.466912</td>\n",
       "      <td>0.468714</td>\n",
       "      <td>0.470516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.806272</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.801563</td>\n",
       "      <td>0.804474</td>\n",
       "      <td>0.807386</td>\n",
       "      <td>0.808626</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483591</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.478460</td>\n",
       "      <td>0.480579</td>\n",
       "      <td>0.482699</td>\n",
       "      <td>0.486156</td>\n",
       "      <td>0.489613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.839624</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.837266</td>\n",
       "      <td>0.837815</td>\n",
       "      <td>0.838364</td>\n",
       "      <td>0.840803</td>\n",
       "      <td>0.843242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.439277</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.434396</td>\n",
       "      <td>0.437435</td>\n",
       "      <td>0.440474</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.442961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_tdidf</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.844323</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.843549</td>\n",
       "      <td>0.843714</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.844710</td>\n",
       "      <td>0.845541</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.402263</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.400776</td>\n",
       "      <td>0.401576</td>\n",
       "      <td>0.402376</td>\n",
       "      <td>0.403006</td>\n",
       "      <td>0.403637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.812810</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.809560</td>\n",
       "      <td>0.810925</td>\n",
       "      <td>0.812289</td>\n",
       "      <td>0.814435</td>\n",
       "      <td>0.816580</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.490701</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.477288</td>\n",
       "      <td>0.479547</td>\n",
       "      <td>0.481806</td>\n",
       "      <td>0.497407</td>\n",
       "      <td>0.513008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lin_reg_1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837377</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.834993</td>\n",
       "      <td>0.835670</td>\n",
       "      <td>0.836347</td>\n",
       "      <td>0.838569</td>\n",
       "      <td>0.840791</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.415738</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>0.413611</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>0.419331</td>\n",
       "      <td>0.419994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lin_reg_2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.845089</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.843637</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.845936</td>\n",
       "      <td>0.847993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.398299</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.395660</td>\n",
       "      <td>0.396992</td>\n",
       "      <td>0.398324</td>\n",
       "      <td>0.399618</td>\n",
       "      <td>0.400911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngram</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.833291</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.829324</td>\n",
       "      <td>0.831610</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.835274</td>\n",
       "      <td>0.836653</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.426563</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.419283</td>\n",
       "      <td>0.422785</td>\n",
       "      <td>0.426287</td>\n",
       "      <td>0.430204</td>\n",
       "      <td>0.434120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformer</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.816844</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.805087</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.821817</td>\n",
       "      <td>0.822723</td>\n",
       "      <td>0.823629</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.461620</td>\n",
       "      <td>0.022916</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0.449378</td>\n",
       "      <td>0.458073</td>\n",
       "      <td>0.472088</td>\n",
       "      <td>0.486103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               average                                                    \\\n",
       "                 count      mean       std       min       25%       50%   \n",
       "model                                                                      \n",
       "LSTM               3.0  0.818990  0.002740  0.816914  0.817437  0.817959   \n",
       "cnn                3.0  0.806272  0.004262  0.801563  0.804474  0.807386   \n",
       "ensemble           3.0  0.839624  0.003181  0.837266  0.837815  0.838364   \n",
       "ensemble_tdidf     3.0  0.844323  0.001068  0.843549  0.843714  0.843879   \n",
       "hybrid             3.0  0.812810  0.003539  0.809560  0.810925  0.812289   \n",
       "lin_reg_1          3.0  0.837377  0.003033  0.834993  0.835670  0.836347   \n",
       "lin_reg_2          3.0  0.845089  0.002526  0.843396  0.843637  0.843879   \n",
       "ngram              3.0  0.833291  0.003702  0.829324  0.831610  0.833895   \n",
       "transformer        3.0  0.816844  0.010222  0.805087  0.813452  0.821817   \n",
       "\n",
       "                                   logloss                                \\\n",
       "                     75%       max   count      mean       std       min   \n",
       "model                                                                      \n",
       "LSTM            0.820028  0.822096     3.0  0.465455  0.005926  0.458935   \n",
       "cnn             0.808626  0.809867     3.0  0.483591  0.005630  0.478460   \n",
       "ensemble        0.840803  0.843242     3.0  0.439277  0.004406  0.434396   \n",
       "ensemble_tdidf  0.844710  0.845541     3.0  0.402263  0.001434  0.400776   \n",
       "hybrid          0.814435  0.816580     3.0  0.490701  0.019450  0.477288   \n",
       "lin_reg_1       0.838569  0.840791     3.0  0.415738  0.006258  0.408553   \n",
       "lin_reg_2       0.845936  0.847993     3.0  0.398299  0.002625  0.395660   \n",
       "ngram           0.835274  0.836653     3.0  0.426563  0.007422  0.419283   \n",
       "transformer     0.822723  0.823629     3.0  0.461620  0.022916  0.440684   \n",
       "\n",
       "                                                        \n",
       "                     25%       50%       75%       max  \n",
       "model                                                   \n",
       "LSTM            0.462924  0.466912  0.468714  0.470516  \n",
       "cnn             0.480579  0.482699  0.486156  0.489613  \n",
       "ensemble        0.437435  0.440474  0.441718  0.442961  \n",
       "ensemble_tdidf  0.401576  0.402376  0.403006  0.403637  \n",
       "hybrid          0.479547  0.481806  0.497407  0.513008  \n",
       "lin_reg_1       0.413611  0.418668  0.419331  0.419994  \n",
       "lin_reg_2       0.396992  0.398324  0.399618  0.400911  \n",
       "ngram           0.422785  0.426287  0.430204  0.434120  \n",
       "transformer     0.449378  0.458073  0.472088  0.486103  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('model').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "df.boxplot('average',by = 'model', ax=ax[0])\n",
    "df.boxplot('logloss',by = 'model', ax=ax[1])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
